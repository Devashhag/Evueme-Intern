{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performing late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Train_Feature.xlsx\")\n",
    "val=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Val_Feature.xlsx\")\n",
    "test=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Test_Feature.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_features = train.iloc[:,10:721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>gaze_1_z</th>\n",
       "      <th>gaze_angle_x</th>\n",
       "      <th>gaze_angle_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU12_c</th>\n",
       "      <th>AU14_c</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.260329</td>\n",
       "      <td>0.197728</td>\n",
       "      <td>-0.933152</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.206567</td>\n",
       "      <td>-0.968903</td>\n",
       "      <td>0.140338</td>\n",
       "      <td>0.209756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159041</td>\n",
       "      <td>0.287582</td>\n",
       "      <td>0.246187</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>0.337691</td>\n",
       "      <td>0.213508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.468410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196817</td>\n",
       "      <td>0.129190</td>\n",
       "      <td>-0.958998</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.111427</td>\n",
       "      <td>-0.978819</td>\n",
       "      <td>0.126841</td>\n",
       "      <td>0.123795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>0.381264</td>\n",
       "      <td>0.331155</td>\n",
       "      <td>0.477124</td>\n",
       "      <td>0.200436</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.257081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.974909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037301</td>\n",
       "      <td>0.354535</td>\n",
       "      <td>-0.920469</td>\n",
       "      <td>-0.233957</td>\n",
       "      <td>0.364587</td>\n",
       "      <td>-0.884906</td>\n",
       "      <td>-0.148632</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080940</td>\n",
       "      <td>0.060052</td>\n",
       "      <td>0.182768</td>\n",
       "      <td>0.219321</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.370757</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083949</td>\n",
       "      <td>0.411877</td>\n",
       "      <td>-0.866863</td>\n",
       "      <td>-0.084308</td>\n",
       "      <td>0.439392</td>\n",
       "      <td>-0.856967</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.460081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108932</td>\n",
       "      <td>0.394336</td>\n",
       "      <td>0.381264</td>\n",
       "      <td>0.344227</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.054466</td>\n",
       "      <td>0.511983</td>\n",
       "      <td>0.220044</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.361656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.246175</td>\n",
       "      <td>0.370730</td>\n",
       "      <td>-0.883701</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.345450</td>\n",
       "      <td>-0.926686</td>\n",
       "      <td>0.151242</td>\n",
       "      <td>0.377732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.272331</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.178649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.198257</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.979864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142412</td>\n",
       "      <td>0.140130</td>\n",
       "      <td>-0.973931</td>\n",
       "      <td>-0.089413</td>\n",
       "      <td>0.248974</td>\n",
       "      <td>-0.957558</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.199223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027248</td>\n",
       "      <td>0.299728</td>\n",
       "      <td>0.059946</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>0.103542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321526</td>\n",
       "      <td>0.188011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.970087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.063541</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>-0.981274</td>\n",
       "      <td>-0.257637</td>\n",
       "      <td>0.163936</td>\n",
       "      <td>-0.942743</td>\n",
       "      <td>-0.165196</td>\n",
       "      <td>0.162486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350763</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>0.237473</td>\n",
       "      <td>0.154684</td>\n",
       "      <td>0.174292</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.966762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.369578</td>\n",
       "      <td>-0.920424</td>\n",
       "      <td>-0.212381</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>-0.866193</td>\n",
       "      <td>-0.115454</td>\n",
       "      <td>0.421914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164491</td>\n",
       "      <td>0.887728</td>\n",
       "      <td>0.187990</td>\n",
       "      <td>0.318538</td>\n",
       "      <td>0.054830</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.370757</td>\n",
       "      <td>0.221932</td>\n",
       "      <td>0.028721</td>\n",
       "      <td>0.287206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.979782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096907</td>\n",
       "      <td>0.053738</td>\n",
       "      <td>-0.991574</td>\n",
       "      <td>-0.172718</td>\n",
       "      <td>0.058386</td>\n",
       "      <td>-0.980676</td>\n",
       "      <td>-0.135863</td>\n",
       "      <td>0.056865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047930</td>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>0.466231</td>\n",
       "      <td>0.093682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298475</td>\n",
       "      <td>0.233115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.974837</td>\n",
       "      <td>0.997821</td>\n",
       "      <td>0.105136</td>\n",
       "      <td>0.420461</td>\n",
       "      <td>-0.883816</td>\n",
       "      <td>-0.154652</td>\n",
       "      <td>0.441973</td>\n",
       "      <td>-0.868693</td>\n",
       "      <td>-0.027906</td>\n",
       "      <td>0.457804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.723312</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.213508</td>\n",
       "      <td>0.139434</td>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.272331</td>\n",
       "      <td>0.213508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       confidence   success   gaze_0_x   gaze_0_y   gaze_0_z   gaze_1_x  \\\n",
       "0        0.974771  1.000000   0.260329   0.197728  -0.933152   0.008025   \n",
       "1        0.928584  1.000000   0.196817   0.129190  -0.958998   0.049780   \n",
       "2        0.974909  1.000000  -0.037301   0.354535  -0.920469  -0.233957   \n",
       "3        0.976819  1.000000   0.083949   0.411877  -0.866863  -0.084308   \n",
       "4        0.978584  1.000000   0.246175   0.370730  -0.883701   0.024941   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "5930     0.979864  1.000000   0.142412   0.140130  -0.973931  -0.089413   \n",
       "5931     0.970087  1.000000  -0.063541   0.151929  -0.981274  -0.257637   \n",
       "5932     0.966762  1.000000   0.005806   0.369578  -0.920424  -0.212381   \n",
       "5933     0.979782  1.000000  -0.096907   0.053738  -0.991574  -0.172718   \n",
       "5934     0.974837  0.997821   0.105136   0.420461  -0.883816  -0.154652   \n",
       "\n",
       "       gaze_1_y   gaze_1_z   gaze_angle_x   gaze_angle_y  ...    AU12_c  \\\n",
       "0      0.206567  -0.968903       0.140338       0.209756  ...  0.631808   \n",
       "1      0.111427  -0.978819       0.126841       0.123795  ...  0.091503   \n",
       "2      0.364587  -0.884906      -0.148632       0.378684  ...  0.080940   \n",
       "3      0.439392  -0.856967       0.008508       0.460081  ...  0.108932   \n",
       "4      0.345450  -0.926686       0.151242       0.377732  ...  0.028322   \n",
       "...         ...        ...            ...            ...  ...       ...   \n",
       "5930   0.248974  -0.957558       0.027166       0.199223  ...  0.027248   \n",
       "5931   0.163936  -0.942743      -0.165196       0.162486  ...  0.350763   \n",
       "5932   0.431177  -0.866193      -0.115454       0.421914  ...  0.164491   \n",
       "5933   0.058386  -0.980676      -0.135863       0.056865  ...  0.047930   \n",
       "5934   0.441973  -0.868693      -0.027906       0.457804  ...  0.592593   \n",
       "\n",
       "        AU14_c    AU15_c    AU17_c    AU20_c    AU23_c    AU25_c    AU26_c  \\\n",
       "0     1.000000  0.159041  0.287582  0.246187  0.673203  0.337691  0.213508   \n",
       "1     0.381264  0.331155  0.477124  0.200436  0.261438  0.424837  0.257081   \n",
       "2     0.060052  0.182768  0.219321  0.052219  0.007833  0.370757  0.208877   \n",
       "3     0.394336  0.381264  0.344227  0.235294  0.054466  0.511983  0.220044   \n",
       "4     0.074074  0.272331  0.294118  0.178649  0.000000  0.352941  0.198257   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5930  0.299728  0.059946  0.226158  0.103542  0.000000  0.321526  0.188011   \n",
       "5931  0.383442  0.237473  0.154684  0.174292  0.017429  0.407407  0.296296   \n",
       "5932  0.887728  0.187990  0.318538  0.054830  0.015666  0.370757  0.221932   \n",
       "5933  0.050109  0.095861  0.466231  0.093682  0.000000  0.298475  0.233115   \n",
       "5934  0.723312  0.039216  0.213508  0.139434  0.015251  0.272331  0.213508   \n",
       "\n",
       "        AU28_c    AU45_c  \n",
       "0     0.000000  0.468410  \n",
       "1     0.000000  0.400871  \n",
       "2     0.000000  0.483029  \n",
       "3     0.039216  0.361656  \n",
       "4     0.030501  0.407407  \n",
       "...        ...       ...  \n",
       "5930  0.000000  0.288828  \n",
       "5931  0.000000  0.250545  \n",
       "5932  0.028721  0.287206  \n",
       "5933  0.000000  0.196078  \n",
       "5934  0.000000  0.324619  \n",
       "\n",
       "[5935 rows x 711 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_features = train.iloc[:,721:1404]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsyll</th>\n",
       "      <th>npause</th>\n",
       "      <th>long_pause</th>\n",
       "      <th>dur(s)</th>\n",
       "      <th>phonationtime(s)</th>\n",
       "      <th>speechrate(nsyll / dur)</th>\n",
       "      <th>articulation rate(nsyll / phonationtime)</th>\n",
       "      <th>ASD(speakingtime / nsyll)</th>\n",
       "      <th>HNR</th>\n",
       "      <th>localJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnetz_3_var</th>\n",
       "      <th>tonnetz_4_var</th>\n",
       "      <th>tonnetz_5_var</th>\n",
       "      <th>tonnetz_6_var</th>\n",
       "      <th>poly_1_mean</th>\n",
       "      <th>poly_2_mean</th>\n",
       "      <th>poly_1_std</th>\n",
       "      <th>poly_2_std</th>\n",
       "      <th>poly_1_var</th>\n",
       "      <th>poly_2_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>3.793830</td>\n",
       "      <td>3.793830</td>\n",
       "      <td>0.263586</td>\n",
       "      <td>5.761763</td>\n",
       "      <td>0.019823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020239</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>1.220787</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>1.320513</td>\n",
       "      <td>2.863816e-08</td>\n",
       "      <td>1.743753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>13.559982</td>\n",
       "      <td>2.616434</td>\n",
       "      <td>2.949856</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>7.881200</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.447918</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.471230</td>\n",
       "      <td>1.929210e-08</td>\n",
       "      <td>0.222058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>14.055982</td>\n",
       "      <td>3.008899</td>\n",
       "      <td>3.272628</td>\n",
       "      <td>0.305565</td>\n",
       "      <td>4.767605</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.033076</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>1.904819</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>2.284673</td>\n",
       "      <td>9.855934e-08</td>\n",
       "      <td>5.219729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>10.487982</td>\n",
       "      <td>2.289380</td>\n",
       "      <td>3.337153</td>\n",
       "      <td>0.299657</td>\n",
       "      <td>5.421238</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028146</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>2.079331</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>2.710881</td>\n",
       "      <td>1.084090e-07</td>\n",
       "      <td>7.348878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>3.205132</td>\n",
       "      <td>3.205132</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>10.053853</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>0.042196</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>1.094016</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.193521</td>\n",
       "      <td>2.003398e-08</td>\n",
       "      <td>1.424493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>8.487982</td>\n",
       "      <td>1.635271</td>\n",
       "      <td>2.945341</td>\n",
       "      <td>0.339519</td>\n",
       "      <td>4.931769</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.827372</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1.475002</td>\n",
       "      <td>4.249415e-08</td>\n",
       "      <td>2.175630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15.247982</td>\n",
       "      <td>11.807982</td>\n",
       "      <td>3.016793</td>\n",
       "      <td>3.895670</td>\n",
       "      <td>0.256695</td>\n",
       "      <td>7.444601</td>\n",
       "      <td>0.023288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.510063</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.827248</td>\n",
       "      <td>1.141537e-08</td>\n",
       "      <td>0.684339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>3.728419</td>\n",
       "      <td>3.728419</td>\n",
       "      <td>0.268210</td>\n",
       "      <td>6.816946</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>2.225002</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>2.234160</td>\n",
       "      <td>1.637177e-07</td>\n",
       "      <td>4.991470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.277982</td>\n",
       "      <td>12.765982</td>\n",
       "      <td>3.403591</td>\n",
       "      <td>4.073326</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>7.957025</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.341459</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.433204</td>\n",
       "      <td>2.978731e-09</td>\n",
       "      <td>0.187666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>12.455982</td>\n",
       "      <td>3.074310</td>\n",
       "      <td>3.773287</td>\n",
       "      <td>0.265021</td>\n",
       "      <td>6.533645</td>\n",
       "      <td>0.021893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>1.642438</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>2.062994</td>\n",
       "      <td>6.127907e-08</td>\n",
       "      <td>4.255944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nsyll  npause  long_pause     dur(s)  phonationtime(s)  \\\n",
       "0        58       0           0  15.287982         15.287982   \n",
       "1        40       3           0  15.287982         13.559982   \n",
       "2        46       1           0  15.287982         14.055982   \n",
       "3        35       6           0  15.287982         10.487982   \n",
       "4        49       0           0  15.287982         15.287982   \n",
       "...     ...     ...         ...        ...               ...   \n",
       "5930     25       4           2  15.287982          8.487982   \n",
       "5931     46       4           0  15.247982         11.807982   \n",
       "5932     57       0           0  15.287982         15.287982   \n",
       "5933     52       3           0  15.277982         12.765982   \n",
       "5934     47       4           0  15.287982         12.455982   \n",
       "\n",
       "      speechrate(nsyll / dur)  articulation rate(nsyll / phonationtime)  \\\n",
       "0                    3.793830                                  3.793830   \n",
       "1                    2.616434                                  2.949856   \n",
       "2                    3.008899                                  3.272628   \n",
       "3                    2.289380                                  3.337153   \n",
       "4                    3.205132                                  3.205132   \n",
       "...                       ...                                       ...   \n",
       "5930                 1.635271                                  2.945341   \n",
       "5931                 3.016793                                  3.895670   \n",
       "5932                 3.728419                                  3.728419   \n",
       "5933                 3.403591                                  4.073326   \n",
       "5934                 3.074310                                  3.773287   \n",
       "\n",
       "      ASD(speakingtime / nsyll)        HNR  localJitter  ...  tonnetz_3_var  \\\n",
       "0                      0.263586   5.761763     0.019823  ...       0.020239   \n",
       "1                      0.339000   7.881200     0.016353  ...       0.026327   \n",
       "2                      0.305565   4.767605     0.017839  ...       0.027958   \n",
       "3                      0.299657   5.421238     0.016886  ...       0.028146   \n",
       "4                      0.312000  10.053853     0.009795  ...       0.036176   \n",
       "...                         ...        ...          ...  ...            ...   \n",
       "5930                   0.339519   4.931769     0.021349  ...       0.025493   \n",
       "5931                   0.256695   7.444601     0.023288  ...       0.043259   \n",
       "5932                   0.268210   6.816946     0.016022  ...       0.044818   \n",
       "5933                   0.245500   7.957025     0.020040  ...       0.029371   \n",
       "5934                   0.265021   6.533645     0.021893  ...       0.027132   \n",
       "\n",
       "      tonnetz_4_var   tonnetz_5_var  tonnetz_6_var   poly_1_mean  poly_2_mean  \\\n",
       "0          0.026564        0.003056       0.003414     -0.000126     1.220787   \n",
       "1          0.023972        0.003701       0.002706     -0.000016     0.447918   \n",
       "2          0.033076        0.004186       0.004257     -0.000179     1.904819   \n",
       "3          0.024582        0.003012       0.003344     -0.000223     2.079331   \n",
       "4          0.042196        0.005526       0.005015     -0.000125     1.094016   \n",
       "...             ...             ...            ...           ...          ...   \n",
       "5930       0.011943        0.002129       0.002478     -0.000071     0.827372   \n",
       "5931       0.036821        0.005145       0.007895     -0.000053     0.510063   \n",
       "5932       0.046435        0.005876       0.005004     -0.000181     2.225002   \n",
       "5933       0.028361        0.003795       0.003763     -0.000038     0.341459   \n",
       "5934       0.019817        0.003169       0.002802     -0.000183     1.642438   \n",
       "\n",
       "      poly_1_std  poly_2_std    poly_1_var   poly_2_var  \n",
       "0       0.000169    1.320513  2.863816e-08     1.743753  \n",
       "1       0.000139    0.471230  1.929210e-08     0.222058  \n",
       "2       0.000314    2.284673  9.855934e-08     5.219729  \n",
       "3       0.000329    2.710881  1.084090e-07     7.348878  \n",
       "4       0.000142    1.193521  2.003398e-08     1.424493  \n",
       "...          ...         ...           ...          ...  \n",
       "5930    0.000206    1.475002  4.249415e-08     2.175630  \n",
       "5931    0.000107    0.827248  1.141537e-08     0.684339  \n",
       "5932    0.000405    2.234160  1.637177e-07     4.991470  \n",
       "5933    0.000055    0.433204  2.978731e-09     0.187666  \n",
       "5934    0.000248    2.062994  6.127907e-08     4.255944  \n",
       "\n",
       "[5935 rows x 683 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_features = train.iloc[:,1404:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Function words</th>\n",
       "      <th>Total Pronouns</th>\n",
       "      <th>Personal Pronouns</th>\n",
       "      <th>1st person Singular</th>\n",
       "      <th>1st person Plural</th>\n",
       "      <th>2nd Person</th>\n",
       "      <th>3rd person Singular</th>\n",
       "      <th>3rd person Plural</th>\n",
       "      <th>Impersonal Pronouns</th>\n",
       "      <th>Articles</th>\n",
       "      <th>...</th>\n",
       "      <th>Achivement</th>\n",
       "      <th>Leisure</th>\n",
       "      <th>Home</th>\n",
       "      <th>Money</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Death</th>\n",
       "      <th>SpokenCategories</th>\n",
       "      <th>Assent</th>\n",
       "      <th>Nonfluencies</th>\n",
       "      <th>Fillers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Function words  Total Pronouns  Personal Pronouns  \\\n",
       "0                 0.350000        0.083333           0.083333   \n",
       "1                 0.319149        0.148936           0.148936   \n",
       "2                 0.343750        0.125000           0.125000   \n",
       "3                 0.307692        0.153846           0.153846   \n",
       "4                 0.357143        0.107143           0.107143   \n",
       "...                    ...             ...                ...   \n",
       "5930              0.400000        0.000000           0.000000   \n",
       "5931              0.384615        0.076923           0.076923   \n",
       "5932              0.350877        0.122807           0.122807   \n",
       "5933              0.400000        0.022222           0.022222   \n",
       "5934              0.400000        0.057143           0.057143   \n",
       "\n",
       "      1st person Singular  1st person Plural  2nd Person  3rd person Singular  \\\n",
       "0                0.083333                0.0    0.000000             0.033333   \n",
       "1                0.106383                0.0    0.000000             0.000000   \n",
       "2                0.125000                0.0    0.000000             0.000000   \n",
       "3                0.153846                0.0    0.025641             0.000000   \n",
       "4                0.107143                0.0    0.035714             0.000000   \n",
       "...                   ...                ...         ...                  ...   \n",
       "5930             0.000000                0.0    0.000000             0.000000   \n",
       "5931             0.076923                0.0    0.025641             0.000000   \n",
       "5932             0.122807                0.0    0.000000             0.000000   \n",
       "5933             0.000000                0.0    0.133333             0.000000   \n",
       "5934             0.085714                0.0    0.028571             0.000000   \n",
       "\n",
       "      3rd person Plural  Impersonal Pronouns  Articles  ...  Achivement  \\\n",
       "0              0.000000             0.033333  0.050000  ...         0.0   \n",
       "1              0.021277             0.000000  0.042553  ...         0.0   \n",
       "2              0.015625             0.000000  0.031250  ...         0.0   \n",
       "3              0.000000             0.000000  0.076923  ...         0.0   \n",
       "4              0.000000             0.000000  0.107143  ...         0.0   \n",
       "...                 ...                  ...       ...  ...         ...   \n",
       "5930           0.000000             0.066667  0.066667  ...         0.0   \n",
       "5931           0.000000             0.000000  0.051282  ...         0.0   \n",
       "5932           0.000000             0.000000  0.087719  ...         0.0   \n",
       "5933           0.000000             0.000000  0.022222  ...         0.0   \n",
       "5934           0.028571             0.057143  0.000000  ...         0.0   \n",
       "\n",
       "       Leisure      Home  Money  Religion  Death  SpokenCategories  Assent  \\\n",
       "0     0.000000  0.000000    0.0       0.0    0.0          0.016667     0.0   \n",
       "1     0.021277  0.021277    0.0       0.0    0.0          0.000000     0.0   \n",
       "2     0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "3     0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "4     0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "...        ...       ...    ...       ...    ...               ...     ...   \n",
       "5930  0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "5931  0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "5932  0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "5933  0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "5934  0.000000  0.000000    0.0       0.0    0.0          0.000000     0.0   \n",
       "\n",
       "      Nonfluencies  Fillers  \n",
       "0              0.0        0  \n",
       "1              0.0        0  \n",
       "2              0.0        0  \n",
       "3              0.0        0  \n",
       "4              0.0        0  \n",
       "...            ...      ...  \n",
       "5930           0.0        0  \n",
       "5931           0.0        0  \n",
       "5932           0.0        0  \n",
       "5933           0.0        0  \n",
       "5934           0.0        0  \n",
       "\n",
       "[5935 rows x 66 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "      <th>interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.504673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.457944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.373832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.457944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.570093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.588785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.616822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.691589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.616822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.429907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      extraversion  neuroticism  agreeableness  conscientiousness  openness  \\\n",
       "0         0.523364     0.552083       0.626374           0.601942  0.488889   \n",
       "1         0.345794     0.375000       0.472527           0.582524  0.366667   \n",
       "2         0.252336     0.291667       0.406593           0.485437  0.511111   \n",
       "3         0.457944     0.489583       0.505495           0.398058  0.377778   \n",
       "4         0.607477     0.489583       0.406593           0.621359  0.622222   \n",
       "...            ...          ...            ...                ...       ...   \n",
       "5930      0.523364     0.479167       0.626374           0.621359  0.544444   \n",
       "5931      0.728972     0.760417       0.582418           0.524272  0.822222   \n",
       "5932      0.700935     0.770833       0.747253           0.699029  0.788889   \n",
       "5933      0.317757     0.531250       0.582418           0.679612  0.588889   \n",
       "5934      0.401869     0.500000       0.461538           0.543689  0.588889   \n",
       "\n",
       "      interview  \n",
       "0      0.504673  \n",
       "1      0.457944  \n",
       "2      0.373832  \n",
       "3      0.457944  \n",
       "4      0.570093  \n",
       "...         ...  \n",
       "5930   0.588785  \n",
       "5931   0.616822  \n",
       "5932   0.691589  \n",
       "5933   0.616822  \n",
       "5934   0.429907  \n",
       "\n",
       "[5935 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_video_features=val.iloc[:,10:721]\n",
    "val_audio_features=val.iloc[:,721:1404]\n",
    "val_text_features=val.iloc[:,1404:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y=val.iloc[:,4:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_features= test.iloc[:,10:721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>gaze_1_z</th>\n",
       "      <th>gaze_angle_x</th>\n",
       "      <th>gaze_angle_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU12_c</th>\n",
       "      <th>AU14_c</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185936</td>\n",
       "      <td>0.349373</td>\n",
       "      <td>-0.892027</td>\n",
       "      <td>-0.165313</td>\n",
       "      <td>0.357158</td>\n",
       "      <td>-0.896048</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>0.376202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566757</td>\n",
       "      <td>0.694823</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.291553</td>\n",
       "      <td>0.152589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365123</td>\n",
       "      <td>0.179837</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>0.427793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.967342</td>\n",
       "      <td>0.986928</td>\n",
       "      <td>0.041329</td>\n",
       "      <td>0.184496</td>\n",
       "      <td>-0.971610</td>\n",
       "      <td>-0.186886</td>\n",
       "      <td>0.267155</td>\n",
       "      <td>-0.930644</td>\n",
       "      <td>-0.076895</td>\n",
       "      <td>0.233525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115468</td>\n",
       "      <td>0.161220</td>\n",
       "      <td>0.056645</td>\n",
       "      <td>0.180828</td>\n",
       "      <td>0.069717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285403</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156488</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>-0.942914</td>\n",
       "      <td>-0.063650</td>\n",
       "      <td>0.276645</td>\n",
       "      <td>-0.951142</td>\n",
       "      <td>0.049111</td>\n",
       "      <td>0.271947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.393130</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>0.973282</td>\n",
       "      <td>0.164122</td>\n",
       "      <td>0.103053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.979564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041926</td>\n",
       "      <td>0.253779</td>\n",
       "      <td>-0.955655</td>\n",
       "      <td>-0.131375</td>\n",
       "      <td>0.295208</td>\n",
       "      <td>-0.937259</td>\n",
       "      <td>-0.045876</td>\n",
       "      <td>0.281610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021786</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.143791</td>\n",
       "      <td>0.311547</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.344227</td>\n",
       "      <td>0.191721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.917473</td>\n",
       "      <td>0.938998</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.216546</td>\n",
       "      <td>-0.953065</td>\n",
       "      <td>-0.076603</td>\n",
       "      <td>0.199708</td>\n",
       "      <td>-0.958491</td>\n",
       "      <td>-0.029830</td>\n",
       "      <td>0.216917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.139434</td>\n",
       "      <td>0.224401</td>\n",
       "      <td>0.400871</td>\n",
       "      <td>0.102397</td>\n",
       "      <td>0.187364</td>\n",
       "      <td>0.335512</td>\n",
       "      <td>0.307190</td>\n",
       "      <td>0.023965</td>\n",
       "      <td>0.313725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.929237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.265173</td>\n",
       "      <td>-0.953968</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.228162</td>\n",
       "      <td>-0.969492</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>0.251268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063181</td>\n",
       "      <td>0.150327</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324619</td>\n",
       "      <td>0.204793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.935948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148214</td>\n",
       "      <td>0.336260</td>\n",
       "      <td>-0.903985</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>0.276739</td>\n",
       "      <td>-0.946607</td>\n",
       "      <td>0.129919</td>\n",
       "      <td>0.321307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289760</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.389978</td>\n",
       "      <td>0.455338</td>\n",
       "      <td>0.141612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357298</td>\n",
       "      <td>0.320261</td>\n",
       "      <td>0.067538</td>\n",
       "      <td>0.440087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.915621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051737</td>\n",
       "      <td>0.167928</td>\n",
       "      <td>-0.970621</td>\n",
       "      <td>0.132746</td>\n",
       "      <td>0.131834</td>\n",
       "      <td>-0.976448</td>\n",
       "      <td>0.094752</td>\n",
       "      <td>0.153102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.886710</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.318083</td>\n",
       "      <td>0.141612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359477</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.883377</td>\n",
       "      <td>0.910675</td>\n",
       "      <td>0.158029</td>\n",
       "      <td>0.195878</td>\n",
       "      <td>-0.932910</td>\n",
       "      <td>-0.089154</td>\n",
       "      <td>0.217308</td>\n",
       "      <td>-0.948310</td>\n",
       "      <td>0.039214</td>\n",
       "      <td>0.217673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788671</td>\n",
       "      <td>0.638344</td>\n",
       "      <td>0.328976</td>\n",
       "      <td>0.220044</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.265795</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.209150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.979478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136966</td>\n",
       "      <td>0.236091</td>\n",
       "      <td>-0.932338</td>\n",
       "      <td>-0.019683</td>\n",
       "      <td>0.230428</td>\n",
       "      <td>-0.940854</td>\n",
       "      <td>0.061057</td>\n",
       "      <td>0.244222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046997</td>\n",
       "      <td>0.161880</td>\n",
       "      <td>0.221932</td>\n",
       "      <td>0.271540</td>\n",
       "      <td>0.172324</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>0.349869</td>\n",
       "      <td>0.203655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1998 rows × 711 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       confidence   success   gaze_0_x   gaze_0_y   gaze_0_z   gaze_1_x  \\\n",
       "0        0.978365  1.000000   0.185936   0.349373  -0.892027  -0.165313   \n",
       "1        0.967342  0.986928   0.041329   0.184496  -0.971610  -0.186886   \n",
       "2        0.979618  1.000000   0.156488   0.251218  -0.942914  -0.063650   \n",
       "3        0.979564  1.000000   0.041926   0.253779  -0.955655  -0.131375   \n",
       "4        0.917473  0.938998   0.016168   0.216546  -0.953065  -0.076603   \n",
       "...           ...       ...        ...        ...        ...        ...   \n",
       "1993     0.929237  1.000000   0.003278   0.265173  -0.953968   0.040522   \n",
       "1994     0.935948  1.000000   0.148214   0.336260  -0.903985   0.087518   \n",
       "1995     0.915621  1.000000   0.051737   0.167928  -0.970621   0.132746   \n",
       "1996     0.883377  0.910675   0.158029   0.195878  -0.932910  -0.089154   \n",
       "1997     0.979478  1.000000   0.136966   0.236091  -0.932338  -0.019683   \n",
       "\n",
       "       gaze_1_y   gaze_1_z   gaze_angle_x   gaze_angle_y  ...    AU12_c  \\\n",
       "0      0.357158  -0.896048       0.013169       0.376202  ...  0.566757   \n",
       "1      0.267155  -0.930644      -0.076895       0.233525  ...  0.115468   \n",
       "2      0.276645  -0.951142       0.049111       0.271947  ...  1.000000   \n",
       "3      0.295208  -0.937259      -0.045876       0.281610  ...  0.021786   \n",
       "4      0.199708  -0.958491      -0.029830       0.216917  ...  0.013072   \n",
       "...         ...        ...            ...            ...  ...       ...   \n",
       "1993   0.228162  -0.969492       0.023410       0.251268  ...  0.000000   \n",
       "1994   0.276739  -0.946607       0.129919       0.321307  ...  0.289760   \n",
       "1995   0.131834  -0.976448       0.094752       0.153102  ...  0.008715   \n",
       "1996   0.217308  -0.948310       0.039214       0.217673  ...  0.788671   \n",
       "1997   0.230428  -0.940854       0.061057       0.244222  ...  0.046997   \n",
       "\n",
       "        AU14_c    AU15_c    AU17_c    AU20_c    AU23_c    AU25_c    AU26_c  \\\n",
       "0     0.694823  0.010899  0.291553  0.152589  0.000000  0.365123  0.179837   \n",
       "1     0.161220  0.056645  0.180828  0.069717  0.000000  0.285403  0.209150   \n",
       "2     0.656489  0.393130  0.480916  0.175573  0.973282  0.164122  0.103053   \n",
       "3     0.052288  0.143791  0.311547  0.185185  0.026144  0.344227  0.191721   \n",
       "4     0.139434  0.224401  0.400871  0.102397  0.187364  0.335512  0.307190   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1993  0.063181  0.150327  0.252723  0.071895  0.000000  0.324619  0.204793   \n",
       "1994  0.629630  0.389978  0.455338  0.141612  0.000000  0.357298  0.320261   \n",
       "1995  0.886710  0.163399  0.318083  0.141612  0.000000  0.359477  0.352941   \n",
       "1996  0.638344  0.328976  0.220044  0.058824  0.000000  0.518519  0.265795   \n",
       "1997  0.161880  0.221932  0.271540  0.172324  0.057441  0.349869  0.203655   \n",
       "\n",
       "        AU28_c    AU45_c  \n",
       "0     0.016349  0.427793  \n",
       "1     0.000000  0.374728  \n",
       "2     0.000000  0.312977  \n",
       "3     0.000000  0.185185  \n",
       "4     0.023965  0.313725  \n",
       "...        ...       ...  \n",
       "1993  0.000000  0.193900  \n",
       "1994  0.067538  0.440087  \n",
       "1995  0.000000  0.252723  \n",
       "1996  0.087146  0.209150  \n",
       "1997  0.000000  0.344648  \n",
       "\n",
       "[1998 rows x 711 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_features=test.iloc[:,721:1404]\n",
    "test_text_features=test.iloc[:,1404:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=test.iloc[:,4:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just extracting the len of the features from audio video and text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_r,audio_feat=train_audio_features.shape\n",
    "audio_feat\n",
    "\n",
    "video_r,video_feat=train_video_features.shape\n",
    "video_feat\n",
    "\n",
    "text_r,text_feat=train_text_features.shape\n",
    "text_feat\n",
    "\n",
    "op_r,op=train_y.shape\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,Sequential,initializers\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)## taking the seed as 42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer=tf.keras.initializers.GlorotUniform()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_input=tf.keras.Input(shape=(audio_feat),name=\"audio_input\")\n",
    "model1=Dense(512,activation=\"relu\",kernel_initializer=initializer)(audio_input)\n",
    "model1=Dropout(0.2)(model1)\n",
    "\n",
    "model1=Dense(256,activation=\"relu\",kernel_initializer=initializer)(audio_input)\n",
    "model1=Dropout(0.2)(model1)\n",
    "\n",
    "model1=Dense(128,activation=\"relu\",kernel_initializer=initializer)(audio_input)\n",
    "model1=Dropout(0.2)(model1)\n",
    "\n",
    "model1=Dense(64,activation=\"relu\",kernel_initializer=initializer)(audio_input)\n",
    "model1=Dropout(0.2)(model1)\n",
    "\n",
    "model1=Dense(32,activation=\"relu\",kernel_initializer=initializer)(audio_input)\n",
    "model1=Dropout(0.2)(model1)\n",
    "\n",
    "output_model_1=Dense(op,activation=\"sigmoid\",kernel_initializer=initializer)(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_1=Model(inputs=audio_input,outputs=output_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " audio_input (InputLayer)    [(None, 683)]             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                21888     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,086\n",
      "Trainable params: 22,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "ES=EarlyStopping(patience=10)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer=Adam()\n",
    "final_model_1.compile(loss=\"mean_absolute_error\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(x_train, x_val, x_test):\n",
    "      \"\"\"\n",
    "      Standard Scale test and train data\n",
    "      Z - Score normalization\n",
    "      \"\"\"\n",
    "      standard_scaler = StandardScaler()\n",
    "      x_train_scaled = pd.DataFrame(\n",
    "          standard_scaler.fit_transform(x_train),\n",
    "          columns=x_train.columns\n",
    "      )\n",
    "      x_val_scaled = pd.DataFrame(\n",
    "          standard_scaler.transform(x_val),\n",
    "          columns = x_test.columns\n",
    "      )\n",
    "      x_test_scaled = pd.DataFrame(\n",
    "          standard_scaler.transform(x_test),\n",
    "          columns = x_test.columns\n",
    "      )\n",
    "      return x_train_scaled,x_val_scaled, x_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_scaled, val_video_scaled, test_video_scaled = scale_datasets(train_video_features, val_video_features ,test_video_features)\n",
    "train_audio_scaled, val_audio_scaled, test_audio_scaled = scale_datasets(train_audio_features, val_audio_features ,test_audio_features)\n",
    "train_text_scaled, val_text_scaled, test_text_scaled = scale_datasets(train_text_features, val_text_features ,test_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1542 - val_loss: 0.1423\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1244 - val_loss: 0.1185\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.1135\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1239\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.1206\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1089\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0987 - val_loss: 0.1151\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.1096\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1269\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1179\n",
      "Epoch 11/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1085\n",
      "Epoch 12/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1129\n",
      "Epoch 13/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.1109\n",
      "Epoch 14/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.1151\n",
      "Epoch 15/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.1112\n",
      "Epoch 16/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1114\n",
      "Epoch 17/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.1106\n",
      "Epoch 18/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.1142\n",
      "Epoch 19/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.1122\n",
      "Epoch 20/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.1095\n",
      "Epoch 21/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1133\n"
     ]
    }
   ],
   "source": [
    "history_1=final_model_1.fit(\n",
    "    x=train_audio_scaled.values,\n",
    "    y=train_y.values,\n",
    "    validation_data=(val_audio_scaled.values,val_y.values),\n",
    "    epochs=50,   \n",
    "    callbacks=ES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_1.save(\"audio_model1.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "video_input=tf.keras.Input(shape=(video_feat),name=\"audio_input\")\n",
    "model2=Dense(512,activation=\"relu\",kernel_initializer=initializer)(video_input)\n",
    "model2=Dropout(0.2)(model2)\n",
    "\n",
    "model2=Dense(256,activation=\"relu\",kernel_initializer=initializer)(video_input)\n",
    "model2=Dropout(0.2)(model2)\n",
    "\n",
    "model2=Dense(128,activation=\"relu\",kernel_initializer=initializer)(video_input)\n",
    "model2=Dropout(0.2)(model2)\n",
    "\n",
    "\n",
    "model2=Dense(64,activation=\"relu\",kernel_initializer=initializer)(video_input)\n",
    "model2=Dropout(0.2)(model2)\n",
    "\n",
    "model2=Dense(32,activation=\"relu\",kernel_initializer=initializer)(video_input)\n",
    "model2=Dropout(0.2)(model2)\n",
    "\n",
    "output_model_2=Dense(op,activation=\"sigmoid\",kernel_initializer=initializer)(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_2=Model(inputs=video_input,outputs=output_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "ES=EarlyStopping(patience=10)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer=Adam()\n",
    "final_model_2.compile(loss=\"mean_absolute_error\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 0.1391 - val_loss: 0.1119\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1079\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1078\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1032\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1077 - val_loss: 0.1020\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1064 - val_loss: 0.1013\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1045 - val_loss: 0.1016\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1011\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.1006\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.1013\n",
      "Epoch 11/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1021 - val_loss: 0.0995\n",
      "Epoch 12/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.1012\n",
      "Epoch 13/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1019 - val_loss: 0.1015\n",
      "Epoch 14/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1018 - val_loss: 0.0995\n",
      "Epoch 15/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1008 - val_loss: 0.1002\n",
      "Epoch 16/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1001\n",
      "Epoch 17/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1001\n",
      "Epoch 18/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.0991\n",
      "Epoch 19/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1000\n",
      "Epoch 20/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1002 - val_loss: 0.1005\n",
      "Epoch 21/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1012\n",
      "Epoch 22/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1005 - val_loss: 0.1002\n",
      "Epoch 23/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.1003\n",
      "Epoch 24/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.0992\n",
      "Epoch 25/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0994 - val_loss: 0.0991\n",
      "Epoch 26/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0995 - val_loss: 0.1013\n",
      "Epoch 27/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.0989\n",
      "Epoch 28/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0993 - val_loss: 0.1002\n",
      "Epoch 29/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0986 - val_loss: 0.0983\n",
      "Epoch 30/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0989 - val_loss: 0.0989\n",
      "Epoch 31/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.0982\n",
      "Epoch 32/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.0978\n",
      "Epoch 33/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.0991\n",
      "Epoch 34/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.0984\n",
      "Epoch 35/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0980 - val_loss: 0.0989\n",
      "Epoch 36/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.1009\n",
      "Epoch 37/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0991\n",
      "Epoch 38/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.0980\n",
      "Epoch 39/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0978 - val_loss: 0.0980\n",
      "Epoch 40/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.0984\n",
      "Epoch 41/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.0978\n",
      "Epoch 42/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0972\n",
      "Epoch 43/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0982\n",
      "Epoch 44/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0969 - val_loss: 0.0980\n",
      "Epoch 45/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0975\n",
      "Epoch 46/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.0977\n",
      "Epoch 47/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0979\n",
      "Epoch 48/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0980\n",
      "Epoch 49/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0964 - val_loss: 0.0979\n",
      "Epoch 50/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.0973\n"
     ]
    }
   ],
   "source": [
    "history_2=final_model_2.fit(\n",
    "    x=train_video_scaled.values,\n",
    "    y=train_y.values,\n",
    "    validation_data=(val_video_scaled.values,val_y.values),\n",
    "    epochs=50,   \n",
    "    callbacks=ES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_2.save(\"video_model1.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_input=tf.keras.Input(shape=(text_feat))\n",
    "model3=Dense(128,activation=\"relu\",kernel_initializer=initializer)(text_input)\n",
    "model3=Dropout(0.2)(model3)\n",
    "\n",
    "model3=Dense(64,activation=\"relu\",kernel_initializer=initializer)(text_input)\n",
    "model3=Dropout(0.2)(model3)\n",
    "\n",
    "model3=Dense(32,activation=\"relu\",kernel_initializer=initializer)(text_input)\n",
    "model3=Dropout(0.2)(model3)\n",
    "\n",
    "output_model_3=Dense(op,activation=\"sigmoid\",kernel_initializer=initializer)(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_3=Model(inputs=text_input,outputs=output_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "ES=EarlyStopping(patience=10)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer=Adam()\n",
    "final_model_3.compile(loss=\"mean_absolute_error\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "186/186 [==============================] - 1s 2ms/step - loss: 0.1598 - val_loss: 0.1312\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 0.1225\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1280 - val_loss: 0.1200\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1238 - val_loss: 0.1185\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1221 - val_loss: 0.1179\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1174\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1199 - val_loss: 0.1173\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1172\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.1171\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1180 - val_loss: 0.1168\n",
      "Epoch 11/50\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.1170\n",
      "Epoch 12/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.1166\n",
      "Epoch 13/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.1169\n",
      "Epoch 14/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.1170\n",
      "Epoch 15/50\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.1170\n",
      "Epoch 16/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.1173\n",
      "Epoch 17/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.1171\n",
      "Epoch 18/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1173\n",
      "Epoch 19/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1169\n",
      "Epoch 20/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1173\n",
      "Epoch 21/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1174\n",
      "Epoch 22/50\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1169\n"
     ]
    }
   ],
   "source": [
    "history_3=final_model_3.fit(\n",
    "    x=train_text_scaled.values,\n",
    "    y=train_y.values,\n",
    "    validation_data=(val_text_scaled.values,val_y.values),\n",
    "    epochs=50,   \n",
    "    callbacks=ES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_3.save(\"text_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "audio_saved_1=load_model(\"audio_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "video_saved_1=load_model(\"video_model1.h5\")\n",
    "text_saved_1=load_model(\"text_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 916us/step\n",
      "186/186 [==============================] - 0s 1ms/step\n",
      "186/186 [==============================] - 0s 865us/step\n"
     ]
    }
   ],
   "source": [
    "prediction1=audio_saved_1.predict(train_audio_scaled.values)\n",
    "prediction2=video_saved_1.predict(train_video_scaled.values)\n",
    "prediction3=text_saved_1.predict(train_text_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=(prediction1+prediction2+prediction3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(train_y.values,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08812680277801758"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraverasion\n",
      "MAE 0.08660639049667401 \n",
      " 1-MAE 0.9133936095033259 \n",
      "\n",
      "neurocitism\n",
      "MAE 0.0891150244222669 \n",
      " 1-MAE 0.9108849755777331 \n",
      "\n",
      "agreeableness\n",
      "MAE 0.08661516636646736 \n",
      " 1-MAE 0.9133848336335326 \n",
      "\n",
      "conscientoiusness\n",
      "MAE 0.09305101510663018 \n",
      " 1-MAE 0.9069489848933698 \n",
      "\n",
      "openess\n",
      "MAE 0.08830154007152705 \n",
      " 1-MAE 0.911698459928473 \n",
      "\n",
      "interview\n",
      "MAE 0.0850716802045405 \n",
      " 1-MAE 0.9149283197954595 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_six=[\"extraverasion\",\"neurocitism\",\"agreeableness\",\"conscientoiusness\",\"openess\",\"interview\"]\n",
    "for i in range(6):\n",
    "    print(big_six[i])\n",
    "    mae=mean_absolute_error(train_y.values[:,i],y_pred_train[:,i])\n",
    "    one_mae=1-mae\n",
    "    print(\"MAE\",mae,\"\\n\",\"1-MAE\",one_mae,\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 746us/step\n"
     ]
    }
   ],
   "source": [
    "prediction1_val=audio_saved_1.predict(val_audio_scaled.values)\n",
    "prediction2_val=video_saved_1.predict(val_video_scaled.values)\n",
    "prediction3_val=text_saved_1.predict(val_text_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val=(prediction1_val+prediction2_val+prediction3_val)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(val_y.values,y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10078135542802437"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraverasion\n",
      "MAE 0.10058116785703029 \n",
      " 1-MAE 0.8994188321429697 \n",
      "\n",
      "neurocitism\n",
      "MAE 0.10292161719649981 \n",
      " 1-MAE 0.8970783828035002 \n",
      "\n",
      "agreeableness\n",
      "MAE 0.0918964523472768 \n",
      " 1-MAE 0.9081035476527232 \n",
      "\n",
      "conscientoiusness\n",
      "MAE 0.10917332710063787 \n",
      " 1-MAE 0.8908266728993621 \n",
      "\n",
      "openess\n",
      "MAE 0.10039821696343872 \n",
      " 1-MAE 0.8996017830365612 \n",
      "\n",
      "interview\n",
      "MAE 0.09971735110326278 \n",
      " 1-MAE 0.9002826488967373 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_six=[\"extraverasion\",\"neurocitism\",\"agreeableness\",\"conscientoiusness\",\"openess\",\"interview\"]\n",
    "for i in range(6):\n",
    "    print(big_six[i])\n",
    "    mae=mean_absolute_error(val_y.values[:,i],y_pred_val[:,i])\n",
    "    one_mae=1-mae\n",
    "    print(\"MAE\",mae,\"\\n\",\"1-MAE\",one_mae,\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "63/63 [==============================] - 0s 736us/step\n"
     ]
    }
   ],
   "source": [
    "prediction1_test=audio_saved_1.predict(test_audio_scaled.values)\n",
    "prediction2_test=video_saved_1.predict(test_video_scaled.values)\n",
    "prediction3_test=text_saved_1.predict(test_text_scaled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=(prediction1_test+prediction2_test+prediction3_test)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(test_y.values,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10206730898650097"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraverasion\n",
      "MAE 0.10223128750355578 \n",
      " 1-MAE 0.8977687124964442 \n",
      "\n",
      "neurocitism\n",
      "MAE 0.10399499116418838 \n",
      " 1-MAE 0.8960050088358116 \n",
      "\n",
      "agreeableness\n",
      "MAE 0.09735922427698883 \n",
      " 1-MAE 0.9026407757230112 \n",
      "\n",
      "conscientoiusness\n",
      "MAE 0.10826998836412798 \n",
      " 1-MAE 0.8917300116358721 \n",
      "\n",
      "openess\n",
      "MAE 0.10022308139776627 \n",
      " 1-MAE 0.8997769186022337 \n",
      "\n",
      "interview\n",
      "MAE 0.100325281212379 \n",
      " 1-MAE 0.899674718787621 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_six=[\"extraverasion\",\"neurocitism\",\"agreeableness\",\"conscientoiusness\",\"openess\",\"interview\"]\n",
    "for i in range(6):\n",
    "    print(big_six[i])\n",
    "    mae=mean_absolute_error(test_y.values[:,i],y_pred_test[:,i])\n",
    "    one_mae=1-mae\n",
    "    print(\"MAE\",mae,\"\\n\",\"1-MAE\",one_mae,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
