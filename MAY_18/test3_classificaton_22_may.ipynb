{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Train_Feature.xlsx\")\n",
    "val=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Val_Feature.xlsx\")\n",
    "test=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Test_Feature.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_features = train.iloc[:,10:721]\n",
    "train_audio_features = train.iloc[:,721:1404]\n",
    "train_text_features = train.iloc[:,1404:]\n",
    "train_y=train.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_video_features=val.iloc[:,10:721]\n",
    "val_audio_features=val.iloc[:,721:1404]\n",
    "val_text_features=val.iloc[:,1404:]\n",
    "val_y=val.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_features= test.iloc[:,10:721]\n",
    "test_audio_features=test.iloc[:,721:1404]\n",
    "test_text_features=test.iloc[:,1404:]\n",
    "test_y=test.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_r,audio_feat=train_audio_features.shape\n",
    "audio_feat\n",
    "\n",
    "video_r,video_feat=train_video_features.shape\n",
    "video_feat\n",
    "\n",
    "text_r,text_feat=train_text_features.shape\n",
    "text_feat\n",
    "\n",
    "op_r,op=train_y.shape\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extraversion         float64\n",
       "neuroticism          float64\n",
       "agreeableness        float64\n",
       "conscientiousness    float64\n",
       "openness             float64\n",
       "interview            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mapper(value):\n",
    "    if value <= 0.3:\n",
    "        return 'low'\n",
    "    elif value <= 0.6:\n",
    "        return 'mid'\n",
    "    else:\n",
    "        return 'high'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y['extraversion_label'] = train_y['extraversion'].apply(lambda x: label_mapper(x))\n",
    "#train_y['neuroticism_label'] = train_y['neuroticism'].apply(lambda x: label_mapper(x))\n",
    "#train_y['agreeableness_label'] =train_y['agreeableness'].apply(lambda x: label_mapper(x))\n",
    "#train_y['conscientiousness_label'] =train_y['conscientiousness'].apply(lambda x: label_mapper(x))\n",
    "#train_y['openness_label'] = train_y['openness'].apply(lambda x: label_mapper(x))\n",
    "#train_y['interview_label'] = train_y['interview'].apply(lambda x: label_mapper(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get value counts for each category column\\nextraversion_counts = train_y[\\'extraversion_label\\'].value_counts()\\nneuroticism_counts = train_y[\\'neuroticism_label\\'].value_counts()\\nagreeableness_counts = train_y[\\'agreeableness_label\\'].value_counts()\\nconscientiousness_counts = train_y[\\'conscientiousness_label\\'].value_counts()\\nopenness_counts = train_y[\\'openness_label\\'].value_counts()\\ninterview_counts=train_y[\\'interview_label\\'].value_counts()\\n# Print the value counts\\nprint(\"Extraversion:\")\\nprint(extraversion_counts)\\nprint()\\n\\nprint(\"Neuroticism:\")\\nprint(neuroticism_counts)\\nprint()\\n\\nprint(\"Agreeableness:\")\\nprint(agreeableness_counts)\\nprint()\\n\\nprint(\"Conscientiousness:\")\\nprint(conscientiousness_counts)\\nprint()\\n\\nprint(\"Openness:\")\\nprint(openness_counts)\\n\\nprint(\"Interview\")\\nprint(interview_counts)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# Get value counts for each category column\n",
    "extraversion_counts = train_y['extraversion_label'].value_counts()\n",
    "neuroticism_counts = train_y['neuroticism_label'].value_counts()\n",
    "agreeableness_counts = train_y['agreeableness_label'].value_counts()\n",
    "conscientiousness_counts = train_y['conscientiousness_label'].value_counts()\n",
    "openness_counts = train_y['openness_label'].value_counts()\n",
    "interview_counts=train_y['interview_label'].value_counts()\n",
    "# Print the value counts\n",
    "print(\"Extraversion:\")\n",
    "print(extraversion_counts)\n",
    "print()\n",
    "\n",
    "print(\"Neuroticism:\")\n",
    "print(neuroticism_counts)\n",
    "print()\n",
    "\n",
    "print(\"Agreeableness:\")\n",
    "print(agreeableness_counts)\n",
    "print()\n",
    "\n",
    "print(\"Conscientiousness:\")\n",
    "print(conscientiousness_counts)\n",
    "print()\n",
    "\n",
    "print(\"Openness:\")\n",
    "print(openness_counts)\n",
    "\n",
    "print(\"Interview\")\n",
    "print(interview_counts)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Define the category names and counts\\ncategories = ['Extraversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness','Interview']\\ncounts = [extraversion_counts, neuroticism_counts, agreeableness_counts, conscientiousness_counts, openness_counts,interview_counts]\\n\\n# Create a bar plot for each category\\nfor category, count in zip(categories, counts):\\n    plt.figure()\\n    plt.bar(count.index, count.values)\\n    plt.title(category)\\n    plt.xlabel('Category')\\n    plt.ylabel('Count')\\n\\n# Show the plots\\nplt.show()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "\n",
    "# Define the category names and counts\n",
    "categories = ['Extraversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness','Interview']\n",
    "counts = [extraversion_counts, neuroticism_counts, agreeableness_counts, conscientiousness_counts, openness_counts,interview_counts]\n",
    "\n",
    "# Create a bar plot for each category\n",
    "for category, count in zip(categories, counts):\n",
    "    plt.figure()\n",
    "    plt.bar(count.index, count.values)\n",
    "    plt.title(category)\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\n# Create subplots for each category column\\nfig, axs = plt.subplots(1, 5, figsize=(15, 5))\\n\\n# Plot histograms for each category column\\naxs[0].hist(train_y['extraversion'], bins=10)\\naxs[0].set_title('Extraversion')\\naxs[1].hist(train_y['neuroticism'], bins=10)\\naxs[1].set_title('Neuroticism')\\naxs[2].hist(train_y['agreeableness'], bins=10)\\naxs[2].set_title('Agreeableness')\\naxs[3].hist(train_y['conscientiousness'], bins=10)\\naxs[3].set_title('Conscientiousness')\\naxs[4].hist(train_y['openness'], bins=10)\\naxs[4].set_title('Openness')\\n\\n# Adjust spacing between subplots\\nplt.tight_layout()\\n\\n# Show the plots\\nplt.show()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create subplots for each category column\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "# Plot histograms for each category column\n",
    "axs[0].hist(train_y['extraversion'], bins=10)\n",
    "axs[0].set_title('Extraversion')\n",
    "axs[1].hist(train_y['neuroticism'], bins=10)\n",
    "axs[1].set_title('Neuroticism')\n",
    "axs[2].hist(train_y['agreeableness'], bins=10)\n",
    "axs[2].set_title('Agreeableness')\n",
    "axs[3].hist(train_y['conscientiousness'], bins=10)\n",
    "axs[3].set_title('Conscientiousness')\n",
    "axs[4].hist(train_y['openness'], bins=10)\n",
    "axs[4].set_title('Openness')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "      <th>interview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.504673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.457944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.373832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.457944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.570093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.588785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.616822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.691589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.616822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.429907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      extraversion  neuroticism  agreeableness  conscientiousness  openness  \\\n",
       "0         0.523364     0.552083       0.626374           0.601942  0.488889   \n",
       "1         0.345794     0.375000       0.472527           0.582524  0.366667   \n",
       "2         0.252336     0.291667       0.406593           0.485437  0.511111   \n",
       "3         0.457944     0.489583       0.505495           0.398058  0.377778   \n",
       "4         0.607477     0.489583       0.406593           0.621359  0.622222   \n",
       "...            ...          ...            ...                ...       ...   \n",
       "5930      0.523364     0.479167       0.626374           0.621359  0.544444   \n",
       "5931      0.728972     0.760417       0.582418           0.524272  0.822222   \n",
       "5932      0.700935     0.770833       0.747253           0.699029  0.788889   \n",
       "5933      0.317757     0.531250       0.582418           0.679612  0.588889   \n",
       "5934      0.401869     0.500000       0.461538           0.543689  0.588889   \n",
       "\n",
       "      interview  \n",
       "0      0.504673  \n",
       "1      0.457944  \n",
       "2      0.373832  \n",
       "3      0.457944  \n",
       "4      0.570093  \n",
       "...         ...  \n",
       "5930   0.588785  \n",
       "5931   0.616822  \n",
       "5932   0.691589  \n",
       "5933   0.616822  \n",
       "5934   0.429907  \n",
       "\n",
       "[5935 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extraversion         float64\n",
       "neuroticism          float64\n",
       "agreeableness        float64\n",
       "conscientiousness    float64\n",
       "openness             float64\n",
       "interview            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.3,0.6,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names=['low','medium','high']\n",
    "# Perform binning on 'train_y' columns\n",
    "train_y['extraversion_bin'] = pd.cut(train_y['extraversion'], bins=bins, labels=group_names)\n",
    "train_y['neuroticism_bin'] = pd.cut(train_y['neuroticism'], bins=bins, labels=group_names)\n",
    "train_y['agreeableness_bin'] = pd.cut(train_y['agreeableness'], bins=bins, labels=group_names)\n",
    "train_y['conscientiousness_bin'] = pd.cut(train_y['conscientiousness'], bins=bins, labels=group_names)\n",
    "train_y['openness_bin'] = pd.cut(train_y['openness'], bins=bins, labels=group_names)\n",
    "train_y['interview_bin'] = pd.cut(train_y['interview'], bins=bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>agreeableness</th>\n",
       "      <th>conscientiousness</th>\n",
       "      <th>openness</th>\n",
       "      <th>interview</th>\n",
       "      <th>extraversion_bin</th>\n",
       "      <th>neuroticism_bin</th>\n",
       "      <th>agreeableness_bin</th>\n",
       "      <th>conscientiousness_bin</th>\n",
       "      <th>openness_bin</th>\n",
       "      <th>interview_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.252336</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.485437</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.373832</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.398058</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.570093</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.588785</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.401869</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.543689</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.429907</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      extraversion  neuroticism  agreeableness  conscientiousness  openness  \\\n",
       "0         0.523364     0.552083       0.626374           0.601942  0.488889   \n",
       "1         0.345794     0.375000       0.472527           0.582524  0.366667   \n",
       "2         0.252336     0.291667       0.406593           0.485437  0.511111   \n",
       "3         0.457944     0.489583       0.505495           0.398058  0.377778   \n",
       "4         0.607477     0.489583       0.406593           0.621359  0.622222   \n",
       "...            ...          ...            ...                ...       ...   \n",
       "5930      0.523364     0.479167       0.626374           0.621359  0.544444   \n",
       "5931      0.728972     0.760417       0.582418           0.524272  0.822222   \n",
       "5932      0.700935     0.770833       0.747253           0.699029  0.788889   \n",
       "5933      0.317757     0.531250       0.582418           0.679612  0.588889   \n",
       "5934      0.401869     0.500000       0.461538           0.543689  0.588889   \n",
       "\n",
       "      interview extraversion_bin neuroticism_bin agreeableness_bin  \\\n",
       "0      0.504673           medium          medium              high   \n",
       "1      0.457944           medium          medium            medium   \n",
       "2      0.373832              low             low            medium   \n",
       "3      0.457944           medium          medium            medium   \n",
       "4      0.570093             high          medium            medium   \n",
       "...         ...              ...             ...               ...   \n",
       "5930   0.588785           medium          medium              high   \n",
       "5931   0.616822             high            high            medium   \n",
       "5932   0.691589             high            high              high   \n",
       "5933   0.616822           medium          medium            medium   \n",
       "5934   0.429907           medium          medium            medium   \n",
       "\n",
       "     conscientiousness_bin openness_bin interview_bin  \n",
       "0                     high       medium        medium  \n",
       "1                   medium       medium        medium  \n",
       "2                   medium       medium        medium  \n",
       "3                   medium       medium        medium  \n",
       "4                     high         high        medium  \n",
       "...                    ...          ...           ...  \n",
       "5930                  high       medium        medium  \n",
       "5931                medium         high          high  \n",
       "5932                  high         high          high  \n",
       "5933                  high       medium          high  \n",
       "5934                medium       medium        medium  \n",
       "\n",
       "[5935 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    3838\n",
       "high      1295\n",
       "low        801\n",
       "Name: extraversion_bin, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['extraversion_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    3501\n",
       "high      1936\n",
       "low        498\n",
       "Name: neuroticism_bin, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['neuroticism_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    3417\n",
       "high      2242\n",
       "low        275\n",
       "Name: agreeableness_bin, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['agreeableness_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    3492\n",
       "high      1975\n",
       "low        467\n",
       "Name: conscientiousness_bin, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['conscientiousness_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    3262\n",
       "high      2407\n",
       "low        265\n",
       "Name: openness_bin, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['openness_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    3692\n",
       "high      1621\n",
       "low        621\n",
       "Name: interview_bin, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['interview_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmin_extraverasion=train_y['extraversion_bin'].value_counts().min()\\nmin_neuro=train_y['neuroticism_bin'].value_counts().min()\\nmin_agree=train_y['agreeableness_bin'].value_counts().min()\\nmin_cons=train_y['conscientiousness_bin'].value_counts().min()\\nmin_openess=train_y['openness_bin'].value_counts().min()\\nmin_interview=train_y['interview_bin'].value_counts().min()\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "min_extraverasion=train_y['extraversion_bin'].value_counts().min()\n",
    "min_neuro=train_y['neuroticism_bin'].value_counts().min()\n",
    "min_agree=train_y['agreeableness_bin'].value_counts().min()\n",
    "min_cons=train_y['conscientiousness_bin'].value_counts().min()\n",
    "min_openess=train_y['openness_bin'].value_counts().min()\n",
    "min_interview=train_y['interview_bin'].value_counts().min()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_extraverasion=train_y.groupby('extraversion_bin').apply(lambda x:x.sample(n=min_extraverasion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_neuro=train_y.groupby('neuroticism_bin').apply(lambda x:x.sample(n=min_neuro))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_agree=train_y.groupby('agreeableness_bin').apply(lambda x:x.sample(n=min_agree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_cons=train_y.groupby('conscientiousness_bin').apply(lambda x:x.sample(n=min_cons))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_opness=train_y.groupby('openness_bin').apply(lambda x:x.sample(n=min_openess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#es_interview=train_y.groupby('interview_bin').apply(lambda x:x.sample(n=min_interview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# Assuming 'data' is your DataFrame\\n\\n# Define the number of bins\\nnum_bins = 3\\n\\n# Define the list of column names\\ncolumns = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness', 'interview']\\n\\n# Perform equal-width or equal-frequency binning on each column\\nfor column in columns:\\n    # Perform binning using either cut or qcut\\n    train_y[f'{column}_bin'] = pd.qcut(train_y[column], q=num_bins, labels=False, duplicates='drop')\\n    # Alternatively, you can use pd.cut for equal-width binning:\\n    # data[f'{column}_bin'] = pd.cut(data[column], bins=num_bins, labels=False)\\n\\n# Print the binned data\\ntrain_y\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = 3\n",
    "\n",
    "# Define the list of column names\n",
    "columns = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness', 'interview']\n",
    "\n",
    "# Perform equal-width or equal-frequency binning on each column\n",
    "for column in columns:\n",
    "    # Perform binning using either cut or qcut\n",
    "    train_y[f'{column}_bin'] = pd.qcut(train_y[column], q=num_bins, labels=False, duplicates='drop')\n",
    "    # Alternatively, you can use pd.cut for equal-width binning:\n",
    "    # data[f'{column}_bin'] = pd.cut(data[column], bins=num_bins, labels=False)\n",
    "\n",
    "# Print the binned data\n",
    "train_y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\n# Assuming 'train_y' is your DataFrame with the 6 columns to be binned\\n\\n# Specify the number of bins and the labels\\nnum_bins = 3\\nlabels = ['low', 'medium', 'high']\\n\\n# List of column names to be binned\\ncolumns_to_bin = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness', 'interview']\\n\\n# Perform equal-frequency binning for each column\\nfor column in columns_to_bin:\\n    train_y[column + '_bin'] = pd.qcut(train_y[column], num_bins, labels=labels)\\n\\n# Print the binned DataFrame\\ntrain_y\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'train_y' is your DataFrame with the 6 columns to be binned\n",
    "\n",
    "# Specify the number of bins and the labels\n",
    "num_bins = 3\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# List of column names to be binned\n",
    "columns_to_bin = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness', 'interview']\n",
    "\n",
    "# Perform equal-frequency binning for each column\n",
    "for column in columns_to_bin:\n",
    "    train_y[column + '_bin'] = pd.qcut(train_y[column], num_bins, labels=labels)\n",
    "\n",
    "# Print the binned DataFrame\n",
    "train_y\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the number of bins\n",
    "num_bins = [0,0.3,0.6,1]\n",
    "\n",
    "# Define the labels for the bins\n",
    "bin_labels = [0,1,2]\n",
    "\n",
    "# List of column names to perform equal-frequency binning on\n",
    "columns = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness', 'interview']\n",
    "\n",
    "# Perform equal-frequency binning for each column\n",
    "for column in columns:\n",
    "    train_y['{}_bin'.format(column)] = pd.qcut(train_y[column], q=num_bins, labels=bin_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for extraversion_bin\n",
      "2    2267\n",
      "0    1839\n",
      "1    1829\n",
      "Name: extraversion_bin, dtype: int64\n",
      "\n",
      "Value counts for neuroticism_bin\n",
      "2    2252\n",
      "0    1900\n",
      "1    1783\n",
      "Name: neuroticism_bin, dtype: int64\n",
      "\n",
      "Value counts for agreeableness_bin\n",
      "2    2242\n",
      "0    1857\n",
      "1    1836\n",
      "Name: agreeableness_bin, dtype: int64\n",
      "\n",
      "Value counts for conscientiousness_bin\n",
      "2    2232\n",
      "1    1895\n",
      "0    1808\n",
      "Name: conscientiousness_bin, dtype: int64\n",
      "\n",
      "Value counts for openness_bin\n",
      "2    2238\n",
      "1    1899\n",
      "0    1798\n",
      "Name: openness_bin, dtype: int64\n",
      "\n",
      "Value counts for interview_bin\n",
      "2    2267\n",
      "0    1857\n",
      "1    1811\n",
      "Name: interview_bin, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have performed equal-frequency binning and added the binned columns to the DataFrame\n",
    "\n",
    "# List of binned column names\n",
    "binned_columns = ['extraversion_bin', 'neuroticism_bin', 'agreeableness_bin', 'conscientiousness_bin', 'openness_bin', 'interview_bin']\n",
    "\n",
    "# Iterate over the binned columns and print the value counts\n",
    "for column in binned_columns:\n",
    "    print(\"Value counts for\", column)\n",
    "    print(train_y[column].value_counts())\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "num_bins = [0,0.3,0.6,1]\n",
    "bin_labels = [0, 1,2]# low ,medium,high\n",
    "\n",
    "columns = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness', 'interview']\n",
    "\n",
    "'''\n",
    "# Perform equal-frequency binning for each column\n",
    "for column in columns:\n",
    "    val_y['{}_bin'.format(column)] = pd.qcut(val_y[column], q=num_bins, labels=bin_labels)\n",
    "\n",
    "'''\n",
    "for column in columns:\n",
    "    val_y['{}_bin'.format(column)] = pd.qcut(val_y[column], q=num_bins,labels=bin_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for extraversion_bin\n",
      "2    780\n",
      "0    635\n",
      "1    579\n",
      "Name: extraversion_bin, dtype: int64\n",
      "\n",
      "Value counts for neuroticism_bin\n",
      "2    752\n",
      "1    624\n",
      "0    618\n",
      "Name: neuroticism_bin, dtype: int64\n",
      "\n",
      "Value counts for agreeableness_bin\n",
      "2    791\n",
      "0    653\n",
      "1    550\n",
      "Name: agreeableness_bin, dtype: int64\n",
      "\n",
      "Value counts for conscientiousness_bin\n",
      "2    760\n",
      "0    632\n",
      "1    602\n",
      "Name: conscientiousness_bin, dtype: int64\n",
      "\n",
      "Value counts for openness_bin\n",
      "2    757\n",
      "1    628\n",
      "0    609\n",
      "Name: openness_bin, dtype: int64\n",
      "\n",
      "Value counts for interview_bin\n",
      "2    765\n",
      "0    622\n",
      "1    607\n",
      "Name: interview_bin, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binned_columns = ['extraversion_bin', 'neuroticism_bin', 'agreeableness_bin', 'conscientiousness_bin', 'openness_bin', 'interview_bin']\n",
    "\n",
    "#\n",
    "for column in binned_columns:\n",
    "    print(\"Value counts for\", column)\n",
    "    print(val_y[column].value_counts())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2238\n",
       "1    1899\n",
       "0    1798\n",
       "Name: openness_bin, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['openness_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPaklEQVR4nO3cf6zddX3H8edLGLoJCWXcNVhaq7ObwUwr6QAznTUaKIir/jEiblCZWzWBTRd168wWjMqGM/tldCjGhsIGDHWOKh3YNYK/onKZDKlOe8OKbeVHXQElJM7ie3+c751n13t7T++9Paft5/lIbu45n+/nfM/ncMvzfvM933NTVUiS2vCUUS9AkjQ8Rl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+HtSTbk6w+DNbxoSR/NqTnqiTPmWHbbyX5zDDWoaNT/HCWjgZJdgK/W1X/Nuq1zFeSAlZU1cSo16Kjj0f6al56/H9BTfAfug5rSXYmeUWSdya5Kcm1SX7QnfZZ1c25DlgGfCrJ40n+qBs/K8mXkjya5D/6TxMluT3JFUm+CDwBvD3J+JTn/sMkm7vb1yR5T9+285Pc3e37S0me341fkuRTffN2JPlY3/1dSVYO8NLPS3Jfku8led/kL6Ukr0/yhb79VZI3dc/zaJIPJsmg/33VHqOvI8lvADcCJwKbgQ8AVNVFwHeAV1XV8VX1l0mWALcA7wFOAt4GfCLJWN/+LgLWAycAHwJ+OcmKvu2vA66fuogkLwQ2Am8Efh74MLA5yVOBO4CXJHlKkmcAxwEv6h73bOB44J4BXutrgFXA6cBa4HcOMPd84FeB5wMXAOcMsH81yujrSPKFqtpSVU8C1wEvOMDc3wa2dPN/XFVbgXHgvL4511TV9qraX1WPATcDFwJ08X8uvV8uU60HPlxVX6mqJ6tqE/BD4Kyqug/4AbAS+HXgNuC7SZ4LvBT4fFX9eIDX+t6q2ldV3wH+dnJdM7iyqh7t5n62e25pWkZfR5IH+24/ATwtybEzzH0m8JvdKY9HkzwKvBg4pW/OrimPuZ6fxPV1wL9U1RMz7PutU/a9FHhGt/0OYDW96N8B3E4v+C/t7g+if2339+17OlP/uxw/4HOoQUZfR4upl6HtAq6rqhP7vp5eVVce4DFbgbHunPuFTHNqp2/fV0zZ989V1Q3d9snov6S7fQcHH/2lfbeXAd8d8HHSARl9HS0eAp7dd/8fgFclOSfJMUmelmR1klNn2kFV/Qj4GPA+eu8DbJ1h6keANyU5s7vy5+lJXpnkhG77HcDLgJ+tqt3A54E19M7/f23A1/P2JIuSLAXeDPzTgI+TDsjo62jxF8Cfdqdb3lZVu+i9AfoOYC+9o/O3M/u/+euBVwAfq6r9002oqnHg9+i9kfwIMAG8vm/7t4HH6cWeqvo+cB/wxe79iEHcDNwF3E3vDemPDvg46YD8cJYkNcQjfUlqyExXPkg6RJK8BPjX6bZVlVfe6JDy9I4kNcTTO5LUkMP69M7JJ59cy5cvH/UyJOmIctddd32vqsam23ZYR3/58uWMj4/PPlGS9H+S3D/TNk/vSFJDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNeSw/nDWsC3fcMuol3BI7bzylaNegqQR80hfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIUZfkhpi9CWpIbNGP8nSJJ9N8o0k25O8uRs/KcnWJDu674u68SR5f5KJJPckOb1vX+u6+TuSrDt0L0uSNJ1BjvT3A2+tqtOAs4BLk5wGbAC2VdUKYFt3H+BcYEX3tR64Cnq/JIDLgTOBM4DLJ39RSJKGY9boV9UDVfXv3e0fAN8ElgBrgU3dtE3Aq7vba4Frq+fLwIlJTgHOAbZW1b6qegTYCqxZyBcjSTqwgzqnn2Q58ELgK8Diqnqg2/QgsLi7vQTY1few3d3YTOOSpCEZOPpJjgc+Abylqr7fv62qCqiFWFCS9UnGk4zv3bt3IXYpSeoMFP0kP0Mv+P9YVf/cDT/Unbah+/5wN74HWNr38FO7sZnG/5+qurqqVlXVqrGxsYN5LZKkWQxy9U6AjwLfrKq/7tu0GZi8AmcdcHPf+MXdVTxnAY91p4FuA85Osqh7A/fsbkySNCTHDjDn14CLgK8nubsbewdwJXBTkjcA9wMXdNu2AOcBE8ATwCUAVbUvybuBO7t576qqfQvxIiRJg5k1+lX1BSAzbH75NPMLuHSGfW0ENh7MAiVJC8dP5EpSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDVkkE/kSkeE5RtuGfUSDqmdV75y1EvQUcAjfUlqiNGXpIYYfUlqiOf0JR0Wjub3ZA6n92M80pekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWqI0Zekhhh9SWrIrNFPsjHJw0nu7Rt7Z5I9Se7uvs7r2/YnSSaSfCvJOX3ja7qxiSQbFv6lSJJmM8iR/jXAmmnG/6aqVnZfWwCSnAa8Fnhe95i/T3JMkmOADwLnAqcBF3ZzJUlDdOxsE6rqc0mWD7i/tcCNVfVD4L+STABndNsmquo+gCQ3dnO/cfBLliTN1XzO6V+W5J7u9M+ibmwJsKtvzu5ubKbxn5JkfZLxJON79+6dx/IkSVPNNfpXAb8IrAQeAP5qoRZUVVdX1aqqWjU2NrZQu5UkMcDpnelU1UOTt5N8BPh0d3cPsLRv6qndGAcYlyQNyZyO9JOc0nf3NcDklT2bgdcmeWqSZwErgK8CdwIrkjwryXH03uzdPPdlS5LmYtYj/SQ3AKuBk5PsBi4HVidZCRSwE3gjQFVtT3ITvTdo9wOXVtWT3X4uA24DjgE2VtX2hX4xkqQDG+TqnQunGf7oAeZfAVwxzfgWYMtBrU6StKD8RK4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDjL4kNcToS1JDZo1+ko1JHk5yb9/YSUm2JtnRfV/UjSfJ+5NMJLknyel9j1nXzd+RZN2heTmSpAMZ5Ej/GmDNlLENwLaqWgFs6+4DnAus6L7WA1dB75cEcDlwJnAGcPnkLwpJ0vDMGv2q+hywb8rwWmBTd3sT8Oq+8Wur58vAiUlOAc4BtlbVvqp6BNjKT/8ikSQdYnM9p7+4qh7obj8ILO5uLwF29c3b3Y3NNC5JGqJ5v5FbVQXUAqwFgCTrk4wnGd+7d+9C7VaSxNyj/1B32obu+8Pd+B5gad+8U7uxmcZ/SlVdXVWrqmrV2NjYHJcnSZrOXKO/GZi8AmcdcHPf+MXdVTxnAY91p4FuA85Osqh7A/fsbkySNETHzjYhyQ3AauDkJLvpXYVzJXBTkjcA9wMXdNO3AOcBE8ATwCUAVbUvybuBO7t576qqqW8OS5IOsVmjX1UXzrDp5dPMLeDSGfazEdh4UKuTJC0oP5ErSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ2ZV/ST7Ezy9SR3Jxnvxk5KsjXJju77om48Sd6fZCLJPUlOX4gXIEka3EIc6b+sqlZW1aru/gZgW1WtALZ19wHOBVZ0X+uBqxbguSVJB+FQnN5ZC2zqbm8CXt03fm31fBk4Mckph+D5JUkzmG/0C/hMkruSrO/GFlfVA93tB4HF3e0lwK6+x+7uxiRJQ3LsPB//4qrak+QXgK1J/rN/Y1VVkjqYHXa/PNYDLFu2bJ7LkyT1m9eRflXt6b4/DHwSOAN4aPK0Tff94W76HmBp38NP7cam7vPqqlpVVavGxsbmszxJ0hRzjn6Spyc5YfI2cDZwL7AZWNdNWwfc3N3eDFzcXcVzFvBY32kgSdIQzOf0zmLgk0km93N9Vd2a5E7gpiRvAO4HLujmbwHOAyaAJ4BL5vHckqQ5mHP0q+o+4AXTjP838PJpxgu4dK7PJ0maPz+RK0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNMfqS1BCjL0kNGXr0k6xJ8q0kE0k2DPv5JallQ41+kmOADwLnAqcBFyY5bZhrkKSWDftI/wxgoqruq6r/AW4E1g55DZLUrGOH/HxLgF1993cDZ/ZPSLIeWN/dfTzJt4a0tlE4GfjesJ4s7x3WMzXDn9+R62j/2T1zpg3Djv6squpq4OpRr2MYkoxX1apRr0Nz48/vyNXyz27Yp3f2AEv77p/ajUmShmDY0b8TWJHkWUmOA14LbB7yGiSpWUM9vVNV+5NcBtwGHANsrKrtw1zDYaaJ01hHMX9+R65mf3apqlGvQZI0JH4iV5IaYvQlqSFGX5Iacthdp380S/Jceh9Q+0pVPd43vqaqbh3dyjSb7me3lt7PD3qXGm+uqm+OblXSwfNIf0iS/AFwM/D7wL1J+v/8xJ+PZlUaRJI/pvcnQwJ8tfsKcIN/NPDIl+SSUa9hmLx6Z0iSfB14UVU9nmQ58HHguqr6uyRfq6oXjnaFmkmSbwPPq6ofTRk/DtheVStGszIthCTfqaplo17HsHh6Z3ieMnlKp6p2JlkNfDzJM+kdNerw9WPgGcD9U8ZP6bbpMJfknpk2AYuHuZZRM/rD81CSlVV1N0B3xH8+sBH4lZGuTLN5C7AtyQ5+8gcDlwHPAS4b1aJ0UBYD5wCPTBkP8KXhL2d0jP7wXAzs7x+oqv3AxUk+PJolaRBVdWuSX6L3p8H738i9s6qeHN3KdBA+DRw/edDVL8ntQ1/NCHlOX5Ia4tU7ktQQoy9JDTH6ktQQoy9JDTH6ktSQ/wXgutPW4JybegAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "binned_columns = ['extraversion_bin', 'neuroticism_bin', 'agreeableness_bin', 'conscientiousness_bin', 'openness_bin', 'interview_bin']\n",
    "\n",
    "for column in binned_columns:\n",
    "    counts = train_y[column].value_counts()\n",
    "    counts.plot(kind='bar')\n",
    "    plt.title(column)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=train_y[['openness','openness_bin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>openness</th>\n",
       "      <th>openness_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.622222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.544444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.788889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.588889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.588889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      openness openness_bin\n",
       "0     0.488889            0\n",
       "1     0.366667            0\n",
       "2     0.511111            1\n",
       "3     0.377778            0\n",
       "4     0.622222            2\n",
       "...        ...          ...\n",
       "5930  0.544444            1\n",
       "5931  0.822222            2\n",
       "5932  0.788889            2\n",
       "5933  0.588889            1\n",
       "5934  0.588889            1\n",
       "\n",
       "[5935 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       openness openness_bin\n",
       "0     0.488889            0\n",
       "1     0.366667            0\n",
       "2     0.511111            1\n",
       "3     0.377778            0\n",
       "4     0.622222            2\n",
       "...        ...          ...\n",
       "5930  0.544444            1\n",
       "5931  0.822222            2\n",
       "5932  0.788889            2\n",
       "5933  0.588889            1\n",
       "5934  0.588889            1\n",
       "\n",
       "[5935 rows x 2 columns]>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_originail_openess_copy=new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>openness</th>\n",
       "      <th>openness_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.511111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.622222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.544444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.788889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>0.588889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>0.588889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      openness openness_bin\n",
       "0     0.488889            0\n",
       "1     0.366667            0\n",
       "2     0.511111            1\n",
       "3     0.377778            0\n",
       "4     0.622222            2\n",
       "...        ...          ...\n",
       "5930  0.544444            1\n",
       "5931  0.822222            2\n",
       "5932  0.788889            2\n",
       "5933  0.588889            1\n",
       "5934  0.588889            1\n",
       "\n",
       "[5935 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_originail_openess_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,Sequential,initializers\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)## taking the seed as 42 \n",
    "initializer=tf.keras.initializers.GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the audio model \n",
    "\n",
    "audio_input=tf.keras.Input(shape=(audio_feat),name=\"audio_input\")\n",
    "audio_subnetwork=Dense(128)(audio_input)\n",
    "\n",
    "## for the video \n",
    "\n",
    "video_input=tf.keras.Input(shape=(video_feat),name=\"video_input\")\n",
    "video_subnetwork=Dense(128)(video_input)\n",
    "\n",
    "## for the text \n",
    "\n",
    "text_input=tf.keras.Input(shape=(text_feat),name=\"text_input\")\n",
    "text_subnetwork=Dense(128)(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=Concatenate()([audio_subnetwork,video_subnetwork,text_subnetwork])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "merged=Dense(512,activation='relu',kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(256,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(128,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(64,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(32,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "output_model=Dense(op,activation=\"softmax\",kernel_initializer=initializer)(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=Model(inputs=[audio_input,video_input,text_input],outputs=output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " audio_input (InputLayer)       [(None, 683)]        0           []                               \n",
      "                                                                                                  \n",
      " video_input (InputLayer)       [(None, 711)]        0           []                               \n",
      "                                                                                                  \n",
      " text_input (InputLayer)        [(None, 66)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          87552       ['audio_input[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 128)          91136       ['video_input[0][0]']            \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          8576        ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 384)          0           ['dense_18[0][0]',               \n",
      "                                                                  'dense_19[0][0]',               \n",
      "                                                                  'dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 512)          197120      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 512)          0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 256)          131328      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 256)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 128)          32896       ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 128)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 64)           8256        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 64)           0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 32)           2080        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 32)           0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 6)            198         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 559,142\n",
      "Trainable params: 559,142\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(x_train, x_val, x_test):\n",
    "      \"\"\"\n",
    "      Standard Scale test and train data\n",
    "      Z - Score normalization\n",
    "      \"\"\"\n",
    "      standard_scaler = StandardScaler()\n",
    "      x_train_scaled = pd.DataFrame(\n",
    "          standard_scaler.fit_transform(x_train),\n",
    "          columns=x_train.columns\n",
    "      )\n",
    "      x_val_scaled = pd.DataFrame(\n",
    "          standard_scaler.transform(x_val),\n",
    "          columns = x_test.columns\n",
    "      )\n",
    "      x_test_scaled = pd.DataFrame(\n",
    "          standard_scaler.transform(x_test),\n",
    "          columns = x_test.columns\n",
    "      )\n",
    "      return x_train_scaled,x_val_scaled, x_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_scaled, val_video_scaled, test_video_scaled = scale_datasets(train_video_features, val_video_features ,test_video_features)\n",
    "train_audio_scaled, val_audio_scaled, test_audio_scaled = scale_datasets(train_audio_features, val_audio_features ,test_audio_features)\n",
    "train_text_scaled, val_text_scaled, test_text_scaled = scale_datasets(train_text_features, val_text_features ,test_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer=Adam()\n",
    "#final_model.compile(loss=spareategoricalCrossentropy(),optimizer=optimizer,metrics=[Accuracy()])\n",
    "final_model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_y=train_y.iloc[:,6:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_y=val_y.iloc[:,6:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion_bin</th>\n",
       "      <th>neuroticism_bin</th>\n",
       "      <th>agreeableness_bin</th>\n",
       "      <th>conscientiousness_bin</th>\n",
       "      <th>openness_bin</th>\n",
       "      <th>interview_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      extraversion_bin  neuroticism_bin  agreeableness_bin  \\\n",
       "0                    1                1                  1   \n",
       "1                    1                0                  0   \n",
       "2                    2                2                  2   \n",
       "3                    0                0                  0   \n",
       "4                    1                1                  1   \n",
       "...                ...              ...                ...   \n",
       "1989                 0                0                  1   \n",
       "1990                 2                2                  0   \n",
       "1991                 2                2                  2   \n",
       "1992                 1                2                  1   \n",
       "1993                 2                2                  2   \n",
       "\n",
       "      conscientiousness_bin  openness_bin  interview_bin  \n",
       "0                         1             1              1  \n",
       "1                         0             2              0  \n",
       "2                         2             2              2  \n",
       "3                         1             0              0  \n",
       "4                         2             2              2  \n",
       "...                     ...           ...            ...  \n",
       "1989                      0             0              0  \n",
       "1990                      1             1              1  \n",
       "1991                      2             2              2  \n",
       "1992                      1             2              2  \n",
       "1993                      2             1              2  \n",
       "\n",
       "[1994 rows x 6 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "ES=EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 2s 6ms/step - loss: nan - accuracy: 0.3205 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: nan - accuracy: 0.3201 - val_loss: nan - val_accuracy: 0.3099\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=final_model.fit(\n",
    "    x=[train_audio_features.values,train_video_features.values,train_text_features.values],\n",
    "    y=new_train_y.iloc[:,1:2].values,\n",
    "    validation_data=([val_audio_features.values,val_video_features.values,val_text_features.values],new_val_y.iloc[:,1:2].values),\n",
    "    epochs=50,   \n",
    "    callbacks=ES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsyll</th>\n",
       "      <th>npause</th>\n",
       "      <th>long_pause</th>\n",
       "      <th>dur(s)</th>\n",
       "      <th>phonationtime(s)</th>\n",
       "      <th>speechrate(nsyll / dur)</th>\n",
       "      <th>articulation rate(nsyll / phonationtime)</th>\n",
       "      <th>ASD(speakingtime / nsyll)</th>\n",
       "      <th>HNR</th>\n",
       "      <th>localJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnetz_3_var</th>\n",
       "      <th>tonnetz_4_var</th>\n",
       "      <th>tonnetz_5_var</th>\n",
       "      <th>tonnetz_6_var</th>\n",
       "      <th>poly_1_mean</th>\n",
       "      <th>poly_2_mean</th>\n",
       "      <th>poly_1_std</th>\n",
       "      <th>poly_2_std</th>\n",
       "      <th>poly_1_var</th>\n",
       "      <th>poly_2_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489181</td>\n",
       "      <td>-1.208394</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>1.022885</td>\n",
       "      <td>0.464182</td>\n",
       "      <td>-0.176254</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>-0.656237</td>\n",
       "      <td>0.388797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987467</td>\n",
       "      <td>-0.451010</td>\n",
       "      <td>-0.669689</td>\n",
       "      <td>-0.458274</td>\n",
       "      <td>-0.049452</td>\n",
       "      <td>-0.084623</td>\n",
       "      <td>-0.325268</td>\n",
       "      <td>-0.158986</td>\n",
       "      <td>-0.439259</td>\n",
       "      <td>-0.335129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.109645</td>\n",
       "      <td>0.681081</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>0.074395</td>\n",
       "      <td>-1.168183</td>\n",
       "      <td>-1.670913</td>\n",
       "      <td>1.483849</td>\n",
       "      <td>0.407034</td>\n",
       "      <td>-0.234992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.532305</td>\n",
       "      <td>-0.646821</td>\n",
       "      <td>-0.351723</td>\n",
       "      <td>-0.810629</td>\n",
       "      <td>1.184409</td>\n",
       "      <td>-1.003758</td>\n",
       "      <td>-0.570133</td>\n",
       "      <td>-1.181452</td>\n",
       "      <td>-0.573399</td>\n",
       "      <td>-0.817987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.576703</td>\n",
       "      <td>-0.578569</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>0.346647</td>\n",
       "      <td>-0.624061</td>\n",
       "      <td>-1.099292</td>\n",
       "      <td>0.828459</td>\n",
       "      <td>-1.154982</td>\n",
       "      <td>0.032065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410374</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>-0.112829</td>\n",
       "      <td>-0.038672</td>\n",
       "      <td>-0.645465</td>\n",
       "      <td>0.728864</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>1.001784</td>\n",
       "      <td>0.564290</td>\n",
       "      <td>0.767854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.553764</td>\n",
       "      <td>2.570557</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>-1.611809</td>\n",
       "      <td>-1.621618</td>\n",
       "      <td>-0.985019</td>\n",
       "      <td>0.712646</td>\n",
       "      <td>-0.827069</td>\n",
       "      <td>-0.139153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396300</td>\n",
       "      <td>-0.600772</td>\n",
       "      <td>-0.691569</td>\n",
       "      <td>-0.493144</td>\n",
       "      <td>-1.146960</td>\n",
       "      <td>0.936402</td>\n",
       "      <td>0.966600</td>\n",
       "      <td>1.514905</td>\n",
       "      <td>0.705659</td>\n",
       "      <td>1.443467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.310232</td>\n",
       "      <td>-1.208394</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>1.022885</td>\n",
       "      <td>-0.352000</td>\n",
       "      <td>-1.218826</td>\n",
       "      <td>0.954594</td>\n",
       "      <td>1.497001</td>\n",
       "      <td>-1.413946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204089</td>\n",
       "      <td>0.730205</td>\n",
       "      <td>0.547863</td>\n",
       "      <td>0.338294</td>\n",
       "      <td>-0.043979</td>\n",
       "      <td>-0.235386</td>\n",
       "      <td>-0.548777</td>\n",
       "      <td>-0.311873</td>\n",
       "      <td>-0.562751</td>\n",
       "      <td>-0.436435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>-2.442001</td>\n",
       "      <td>1.310906</td>\n",
       "      <td>4.612553</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>-2.709599</td>\n",
       "      <td>-2.528488</td>\n",
       "      <td>-1.678910</td>\n",
       "      <td>1.494037</td>\n",
       "      <td>-1.072624</td>\n",
       "      <td>0.663110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594644</td>\n",
       "      <td>-1.555813</td>\n",
       "      <td>-1.126885</td>\n",
       "      <td>-0.923892</td>\n",
       "      <td>0.567325</td>\n",
       "      <td>-0.552493</td>\n",
       "      <td>-0.027277</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>-0.240390</td>\n",
       "      <td>-0.198087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>-0.576703</td>\n",
       "      <td>1.310906</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.141356</td>\n",
       "      <td>-0.887268</td>\n",
       "      <td>-0.613118</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>-0.129487</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>1.011669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733722</td>\n",
       "      <td>0.324042</td>\n",
       "      <td>0.360139</td>\n",
       "      <td>1.771560</td>\n",
       "      <td>0.763407</td>\n",
       "      <td>-0.929852</td>\n",
       "      <td>-0.828893</td>\n",
       "      <td>-0.752836</td>\n",
       "      <td>-0.686451</td>\n",
       "      <td>-0.671298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.400358</td>\n",
       "      <td>-1.208394</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>1.022885</td>\n",
       "      <td>0.373495</td>\n",
       "      <td>-0.292096</td>\n",
       "      <td>0.096230</td>\n",
       "      <td>-0.126877</td>\n",
       "      <td>-0.294411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850308</td>\n",
       "      <td>1.050559</td>\n",
       "      <td>0.720216</td>\n",
       "      <td>0.332929</td>\n",
       "      <td>-0.675908</td>\n",
       "      <td>1.109641</td>\n",
       "      <td>1.575007</td>\n",
       "      <td>0.940971</td>\n",
       "      <td>1.499481</td>\n",
       "      <td>0.695424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>-0.043761</td>\n",
       "      <td>0.681081</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.192029</td>\n",
       "      <td>-0.361427</td>\n",
       "      <td>-0.076853</td>\n",
       "      <td>0.318727</td>\n",
       "      <td>-0.348944</td>\n",
       "      <td>0.445074</td>\n",
       "      <td>0.427808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304701</td>\n",
       "      <td>-0.315195</td>\n",
       "      <td>-0.305477</td>\n",
       "      <td>-0.284524</td>\n",
       "      <td>0.937862</td>\n",
       "      <td>-1.130366</td>\n",
       "      <td>-1.250817</td>\n",
       "      <td>-1.227233</td>\n",
       "      <td>-0.807538</td>\n",
       "      <td>-0.828900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>-0.487879</td>\n",
       "      <td>1.310906</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.208920</td>\n",
       "      <td>-0.531585</td>\n",
       "      <td>-0.533374</td>\n",
       "      <td>-0.212634</td>\n",
       "      <td>0.033713</td>\n",
       "      <td>-0.269002</td>\n",
       "      <td>0.760996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472104</td>\n",
       "      <td>-0.960828</td>\n",
       "      <td>-0.613923</td>\n",
       "      <td>-0.762893</td>\n",
       "      <td>-0.692171</td>\n",
       "      <td>0.416826</td>\n",
       "      <td>0.306978</td>\n",
       "      <td>0.734902</td>\n",
       "      <td>0.029222</td>\n",
       "      <td>0.462030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         nsyll    npause  long_pause    dur(s)  phonationtime(s)  \\\n",
       "0     0.489181 -1.208394   -0.345430  0.208920          1.022885   \n",
       "1    -1.109645  0.681081   -0.345430  0.208920          0.074395   \n",
       "2    -0.576703 -0.578569   -0.345430  0.208920          0.346647   \n",
       "3    -1.553764  2.570557   -0.345430  0.208920         -1.611809   \n",
       "4    -0.310232 -1.208394   -0.345430  0.208920          1.022885   \n",
       "...        ...       ...         ...       ...               ...   \n",
       "5930 -2.442001  1.310906    4.612553  0.208920         -2.709599   \n",
       "5931 -0.576703  1.310906   -0.345430  0.141356         -0.887268   \n",
       "5932  0.400358 -1.208394   -0.345430  0.208920          1.022885   \n",
       "5933 -0.043761  0.681081   -0.345430  0.192029         -0.361427   \n",
       "5934 -0.487879  1.310906   -0.345430  0.208920         -0.531585   \n",
       "\n",
       "      speechrate(nsyll / dur)  articulation rate(nsyll / phonationtime)  \\\n",
       "0                    0.464182                                 -0.176254   \n",
       "1                   -1.168183                                 -1.670913   \n",
       "2                   -0.624061                                 -1.099292   \n",
       "3                   -1.621618                                 -0.985019   \n",
       "4                   -0.352000                                 -1.218826   \n",
       "...                       ...                                       ...   \n",
       "5930                -2.528488                                 -1.678910   \n",
       "5931                -0.613118                                  0.004103   \n",
       "5932                 0.373495                                 -0.292096   \n",
       "5933                -0.076853                                  0.318727   \n",
       "5934                -0.533374                                 -0.212634   \n",
       "\n",
       "      ASD(speakingtime / nsyll)       HNR  localJitter  ...  tonnetz_3_var  \\\n",
       "0                      0.005584 -0.656237     0.388797  ...      -0.987467   \n",
       "1                      1.483849  0.407034    -0.234992  ...      -0.532305   \n",
       "2                      0.828459 -1.154982     0.032065  ...      -0.410374   \n",
       "3                      0.712646 -0.827069    -0.139153  ...      -0.396300   \n",
       "4                      0.954594  1.497001    -1.413946  ...       0.204089   \n",
       "...                         ...       ...          ...  ...            ...   \n",
       "5930                   1.494037 -1.072624     0.663110  ...      -0.594644   \n",
       "5931                  -0.129487  0.188003     1.011669  ...       0.733722   \n",
       "5932                   0.096230 -0.126877    -0.294411  ...       0.850308   \n",
       "5933                  -0.348944  0.445074     0.427808  ...      -0.304701   \n",
       "5934                   0.033713 -0.269002     0.760996  ...      -0.472104   \n",
       "\n",
       "      tonnetz_4_var   tonnetz_5_var  tonnetz_6_var   poly_1_mean  poly_2_mean  \\\n",
       "0         -0.451010       -0.669689      -0.458274     -0.049452    -0.084623   \n",
       "1         -0.646821       -0.351723      -0.810629      1.184409    -1.003758   \n",
       "2          0.041097       -0.112829      -0.038672     -0.645465     0.728864   \n",
       "3         -0.600772       -0.691569      -0.493144     -1.146960     0.936402   \n",
       "4          0.730205        0.547863       0.338294     -0.043979    -0.235386   \n",
       "...             ...             ...            ...           ...          ...   \n",
       "5930      -1.555813       -1.126885      -0.923892      0.567325    -0.552493   \n",
       "5931       0.324042        0.360139       1.771560      0.763407    -0.929852   \n",
       "5932       1.050559        0.720216       0.332929     -0.675908     1.109641   \n",
       "5933      -0.315195       -0.305477      -0.284524      0.937862    -1.130366   \n",
       "5934      -0.960828       -0.613923      -0.762893     -0.692171     0.416826   \n",
       "\n",
       "      poly_1_std  poly_2_std   poly_1_var   poly_2_var  \n",
       "0      -0.325268   -0.158986    -0.439259    -0.335129  \n",
       "1      -0.570133   -1.181452    -0.573399    -0.817987  \n",
       "2       0.842975    1.001784     0.564290     0.767854  \n",
       "3       0.966600    1.514905     0.705659     1.443467  \n",
       "4      -0.548777   -0.311873    -0.562751    -0.436435  \n",
       "...          ...         ...          ...          ...  \n",
       "5930   -0.027277    0.027007    -0.240390    -0.198087  \n",
       "5931   -0.828893   -0.752836    -0.686451    -0.671298  \n",
       "5932    1.575007    0.940971     1.499481     0.695424  \n",
       "5933   -1.250817   -1.227233    -0.807538    -0.828900  \n",
       "5934    0.306978    0.734902     0.029222     0.462030  \n",
       "\n",
       "[5935 rows x 683 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_audio_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsyll</th>\n",
       "      <th>npause</th>\n",
       "      <th>long_pause</th>\n",
       "      <th>dur(s)</th>\n",
       "      <th>phonationtime(s)</th>\n",
       "      <th>speechrate(nsyll / dur)</th>\n",
       "      <th>articulation rate(nsyll / phonationtime)</th>\n",
       "      <th>ASD(speakingtime / nsyll)</th>\n",
       "      <th>HNR</th>\n",
       "      <th>localJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnetz_3_var</th>\n",
       "      <th>tonnetz_4_var</th>\n",
       "      <th>tonnetz_5_var</th>\n",
       "      <th>tonnetz_6_var</th>\n",
       "      <th>poly_1_mean</th>\n",
       "      <th>poly_2_mean</th>\n",
       "      <th>poly_1_std</th>\n",
       "      <th>poly_2_std</th>\n",
       "      <th>poly_1_var</th>\n",
       "      <th>poly_2_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>3.793830</td>\n",
       "      <td>3.793830</td>\n",
       "      <td>0.263586</td>\n",
       "      <td>5.761763</td>\n",
       "      <td>0.019823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020239</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>1.220787</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>1.320513</td>\n",
       "      <td>2.863816e-08</td>\n",
       "      <td>1.743753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>13.559982</td>\n",
       "      <td>2.616434</td>\n",
       "      <td>2.949856</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>7.881200</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.447918</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.471230</td>\n",
       "      <td>1.929210e-08</td>\n",
       "      <td>0.222058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>14.055982</td>\n",
       "      <td>3.008899</td>\n",
       "      <td>3.272628</td>\n",
       "      <td>0.305565</td>\n",
       "      <td>4.767605</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>0.033076</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>1.904819</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>2.284673</td>\n",
       "      <td>9.855934e-08</td>\n",
       "      <td>5.219729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>10.487982</td>\n",
       "      <td>2.289380</td>\n",
       "      <td>3.337153</td>\n",
       "      <td>0.299657</td>\n",
       "      <td>5.421238</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028146</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>2.079331</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>2.710881</td>\n",
       "      <td>1.084090e-07</td>\n",
       "      <td>7.348878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>3.205132</td>\n",
       "      <td>3.205132</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>10.053853</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036176</td>\n",
       "      <td>0.042196</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>1.094016</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.193521</td>\n",
       "      <td>2.003398e-08</td>\n",
       "      <td>1.424493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>8.487982</td>\n",
       "      <td>1.635271</td>\n",
       "      <td>2.945341</td>\n",
       "      <td>0.339519</td>\n",
       "      <td>4.931769</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.827372</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1.475002</td>\n",
       "      <td>4.249415e-08</td>\n",
       "      <td>2.175630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15.247982</td>\n",
       "      <td>11.807982</td>\n",
       "      <td>3.016793</td>\n",
       "      <td>3.895670</td>\n",
       "      <td>0.256695</td>\n",
       "      <td>7.444601</td>\n",
       "      <td>0.023288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043259</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.510063</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.827248</td>\n",
       "      <td>1.141537e-08</td>\n",
       "      <td>0.684339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>3.728419</td>\n",
       "      <td>3.728419</td>\n",
       "      <td>0.268210</td>\n",
       "      <td>6.816946</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>2.225002</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>2.234160</td>\n",
       "      <td>1.637177e-07</td>\n",
       "      <td>4.991470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.277982</td>\n",
       "      <td>12.765982</td>\n",
       "      <td>3.403591</td>\n",
       "      <td>4.073326</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>7.957025</td>\n",
       "      <td>0.020040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029371</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.341459</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.433204</td>\n",
       "      <td>2.978731e-09</td>\n",
       "      <td>0.187666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15.287982</td>\n",
       "      <td>12.455982</td>\n",
       "      <td>3.074310</td>\n",
       "      <td>3.773287</td>\n",
       "      <td>0.265021</td>\n",
       "      <td>6.533645</td>\n",
       "      <td>0.021893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>1.642438</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>2.062994</td>\n",
       "      <td>6.127907e-08</td>\n",
       "      <td>4.255944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5935 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nsyll  npause  long_pause     dur(s)  phonationtime(s)  \\\n",
       "0        58       0           0  15.287982         15.287982   \n",
       "1        40       3           0  15.287982         13.559982   \n",
       "2        46       1           0  15.287982         14.055982   \n",
       "3        35       6           0  15.287982         10.487982   \n",
       "4        49       0           0  15.287982         15.287982   \n",
       "...     ...     ...         ...        ...               ...   \n",
       "5930     25       4           2  15.287982          8.487982   \n",
       "5931     46       4           0  15.247982         11.807982   \n",
       "5932     57       0           0  15.287982         15.287982   \n",
       "5933     52       3           0  15.277982         12.765982   \n",
       "5934     47       4           0  15.287982         12.455982   \n",
       "\n",
       "      speechrate(nsyll / dur)  articulation rate(nsyll / phonationtime)  \\\n",
       "0                    3.793830                                  3.793830   \n",
       "1                    2.616434                                  2.949856   \n",
       "2                    3.008899                                  3.272628   \n",
       "3                    2.289380                                  3.337153   \n",
       "4                    3.205132                                  3.205132   \n",
       "...                       ...                                       ...   \n",
       "5930                 1.635271                                  2.945341   \n",
       "5931                 3.016793                                  3.895670   \n",
       "5932                 3.728419                                  3.728419   \n",
       "5933                 3.403591                                  4.073326   \n",
       "5934                 3.074310                                  3.773287   \n",
       "\n",
       "      ASD(speakingtime / nsyll)        HNR  localJitter  ...  tonnetz_3_var  \\\n",
       "0                      0.263586   5.761763     0.019823  ...       0.020239   \n",
       "1                      0.339000   7.881200     0.016353  ...       0.026327   \n",
       "2                      0.305565   4.767605     0.017839  ...       0.027958   \n",
       "3                      0.299657   5.421238     0.016886  ...       0.028146   \n",
       "4                      0.312000  10.053853     0.009795  ...       0.036176   \n",
       "...                         ...        ...          ...  ...            ...   \n",
       "5930                   0.339519   4.931769     0.021349  ...       0.025493   \n",
       "5931                   0.256695   7.444601     0.023288  ...       0.043259   \n",
       "5932                   0.268210   6.816946     0.016022  ...       0.044818   \n",
       "5933                   0.245500   7.957025     0.020040  ...       0.029371   \n",
       "5934                   0.265021   6.533645     0.021893  ...       0.027132   \n",
       "\n",
       "      tonnetz_4_var   tonnetz_5_var  tonnetz_6_var   poly_1_mean  poly_2_mean  \\\n",
       "0          0.026564        0.003056       0.003414     -0.000126     1.220787   \n",
       "1          0.023972        0.003701       0.002706     -0.000016     0.447918   \n",
       "2          0.033076        0.004186       0.004257     -0.000179     1.904819   \n",
       "3          0.024582        0.003012       0.003344     -0.000223     2.079331   \n",
       "4          0.042196        0.005526       0.005015     -0.000125     1.094016   \n",
       "...             ...             ...            ...           ...          ...   \n",
       "5930       0.011943        0.002129       0.002478     -0.000071     0.827372   \n",
       "5931       0.036821        0.005145       0.007895     -0.000053     0.510063   \n",
       "5932       0.046435        0.005876       0.005004     -0.000181     2.225002   \n",
       "5933       0.028361        0.003795       0.003763     -0.000038     0.341459   \n",
       "5934       0.019817        0.003169       0.002802     -0.000183     1.642438   \n",
       "\n",
       "      poly_1_std  poly_2_std    poly_1_var   poly_2_var  \n",
       "0       0.000169    1.320513  2.863816e-08     1.743753  \n",
       "1       0.000139    0.471230  1.929210e-08     0.222058  \n",
       "2       0.000314    2.284673  9.855934e-08     5.219729  \n",
       "3       0.000329    2.710881  1.084090e-07     7.348878  \n",
       "4       0.000142    1.193521  2.003398e-08     1.424493  \n",
       "...          ...         ...           ...          ...  \n",
       "5930    0.000206    1.475002  4.249415e-08     2.175630  \n",
       "5931    0.000107    0.827248  1.141537e-08     0.684339  \n",
       "5932    0.000405    2.234160  1.637177e-07     4.991470  \n",
       "5933    0.000055    0.433204  2.978731e-09     0.187666  \n",
       "5934    0.000248    2.062994  6.127907e-08     4.255944  \n",
       "\n",
       "[5935 rows x 683 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
