{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Train_Feature.xlsx\")\n",
    "val=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Val_Feature.xlsx\")\n",
    "test=pd.read_excel(\"D:\\EVUEME\\MAY\\MAY_18\\Test_Feature.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_features = train.iloc[:,10:721]\n",
    "train_audio_features = train.iloc[:,721:1404]\n",
    "train_text_features = train.iloc[:,1404:]\n",
    "train_y=train.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_video_features=val.iloc[:,10:721]\n",
    "val_audio_features=val.iloc[:,721:1404]\n",
    "val_text_features=val.iloc[:,1404:]\n",
    "val_y=val.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_features= test.iloc[:,10:721]\n",
    "test_audio_features=test.iloc[:,721:1404]\n",
    "test_text_features=test.iloc[:,1404:]\n",
    "test_y=test.iloc[:,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_r,audio_feat=train_audio_features.shape\n",
    "audio_feat\n",
    "\n",
    "video_r,video_feat=train_video_features.shape\n",
    "video_feat\n",
    "\n",
    "text_r,text_feat=train_text_features.shape\n",
    "text_feat\n",
    "\n",
    "op_r,op=train_y.shape\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,Sequential,initializers\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.random.set_seed(42)## taking the seed as 42 \n",
    "initializer=tf.keras.initializers.GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for the audio model \n",
    "\n",
    "audio_input=tf.keras.Input(shape=(audio_feat),name=\"audio_input\")\n",
    "audio_subnetwork=Dense(64)(audio_input)\n",
    "\n",
    "## for the video \n",
    "\n",
    "video_input=tf.keras.Input(shape=(video_feat),name=\"video_input\")\n",
    "video_subnetwork=Dense(64)(video_input)\n",
    "\n",
    "## for the text \n",
    "\n",
    "text_input=tf.keras.Input(shape=(text_feat),name=\"text_input\")\n",
    "text_subnetwork=Dense(64)(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=Concatenate()([audio_subnetwork,video_subnetwork,text_subnetwork])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "merged=Dense(512,activation='relu',kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(256,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(128,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(64,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "merged=Dense(32,activation=\"relu\",kernel_initializer=initializer)(merged)\n",
    "merged=Dropout(0.2)(merged)\n",
    "\n",
    "output_model=Dense(op,activation=\"sigmoid\",kernel_initializer=initializer)(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=Model(inputs=[audio_input,video_input,text_input],outputs=output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " audio_input (InputLayer)       [(None, 683)]        0           []                               \n",
      "                                                                                                  \n",
      " video_input (InputLayer)       [(None, 711)]        0           []                               \n",
      "                                                                                                  \n",
      " text_input (InputLayer)        [(None, 66)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           43776       ['audio_input[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           45568       ['video_input[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           4288        ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192)          0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          98816       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          131328      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           8256        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 32)           2080        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 32)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 6)            198         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 367,206\n",
      "Trainable params: 367,206\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "ES=EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer=Adam()\n",
    "final_model.compile(loss=\"mean_absolute_error\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(x_train, x_val, x_test):\n",
    "      \"\"\"\n",
    "      Standard Scale test and train data\n",
    "      Z - Score normalization\n",
    "      \"\"\"\n",
    "      standard_scaler = StandardScaler()\n",
    "      x_train_scaled = pd.DataFrame(\n",
    "          standard_scaler.fit_transform(x_train),\n",
    "          columns=x_train.columns\n",
    "      )\n",
    "      x_val_scaled = pd.DataFrame(\n",
    "          standard_scaler.transform(x_val),\n",
    "          columns = x_test.columns\n",
    "      )\n",
    "      x_test_scaled = pd.DataFrame(\n",
    "          standard_scaler.transform(x_test),\n",
    "          columns = x_test.columns\n",
    "      )\n",
    "      return x_train_scaled,x_val_scaled, x_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video_scaled, val_video_scaled, test_video_scaled = scale_datasets(train_video_features, val_video_features ,test_video_features)\n",
    "train_audio_scaled, val_audio_scaled, test_audio_scaled = scale_datasets(train_audio_features, val_audio_features ,test_audio_features)\n",
    "train_text_scaled, val_text_scaled, test_text_scaled = scale_datasets(train_text_features, val_text_features ,test_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "186/186 [==============================] - 3s 6ms/step - loss: 0.1179 - val_loss: 0.1078\n",
      "Epoch 2/50\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.1075 - val_loss: 0.1068\n",
      "Epoch 3/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1030 - val_loss: 0.1018\n",
      "Epoch 4/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.0987\n",
      "Epoch 5/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.0995\n",
      "Epoch 6/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0985 - val_loss: 0.1019\n",
      "Epoch 7/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.1005\n",
      "Epoch 8/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.0987\n",
      "Epoch 9/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0946 - val_loss: 0.1016\n",
      "Epoch 10/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0937 - val_loss: 0.1016\n",
      "Epoch 11/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0922 - val_loss: 0.1007\n",
      "Epoch 12/50\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0922 - val_loss: 0.1007\n",
      "Epoch 13/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0899 - val_loss: 0.0994\n",
      "Epoch 14/50\n",
      "186/186 [==============================] - 1s 5ms/step - loss: 0.0888 - val_loss: 0.0994\n"
     ]
    }
   ],
   "source": [
    "history=final_model.fit(\n",
    "    x=[train_audio_scaled.values,train_video_scaled.values,train_text_scaled.values],\n",
    "    y=train_y.values,\n",
    "    validation_data=([val_audio_scaled.values,val_video_scaled.values,val_text_scaled.values],val_y.values),\n",
    "    epochs=50,   \n",
    "    callbacks=ES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=final_model.predict([train_audio_scaled.values,train_video_scaled.values,train_text_scaled.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(train_y.values,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraverasion\n",
      "MAE 0.0827029239548843 \n",
      " 1-MAE 0.9172970760451157 \n",
      "\n",
      "neurocitism\n",
      "MAE 0.0813742857603202 \n",
      " 1-MAE 0.9186257142396798 \n",
      "\n",
      "agreeableness\n",
      "MAE 0.08354553642194226 \n",
      " 1-MAE 0.9164544635780577 \n",
      "\n",
      "conscientoiusness\n",
      "MAE 0.09330664247942545 \n",
      " 1-MAE 0.9066933575205746 \n",
      "\n",
      "openess\n",
      "MAE 0.083196969573656 \n",
      " 1-MAE 0.916803030426344 \n",
      "\n",
      "interview\n",
      "MAE 0.07914737054286376 \n",
      " 1-MAE 0.9208526294571362 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_six=[\"extraverasion\",\"neurocitism\",\"agreeableness\",\"conscientoiusness\",\"openess\",\"interview\"]\n",
    "for i in range(6):\n",
    "    print(big_six[i])\n",
    "    mae=mean_absolute_error(train_y.values[:,i],y_pred[:,i])\n",
    "    one_mae=1-mae\n",
    "    print(\"MAE\",mae,\"\\n\",\"1-MAE\",one_mae,\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09942523867332698"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_validation=final_model.predict([val_audio_scaled.values,val_video_scaled.values,val_text_scaled.values])\n",
    "mae=mean_absolute_error(val_y.values,y_pred_validation)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraverasion\n",
      "MAE 0.09846114991931779 \n",
      " 1-MAE 0.9015388500806822 \n",
      "\n",
      "neurocitism\n",
      "MAE 0.1018157776968883 \n",
      " 1-MAE 0.8981842223031117 \n",
      "\n",
      "agreeableness\n",
      "MAE 0.09154704195504884 \n",
      " 1-MAE 0.9084529580449512 \n",
      "\n",
      "conscientoiusness\n",
      "MAE 0.109336116583476 \n",
      " 1-MAE 0.890663883416524 \n",
      "\n",
      "openess\n",
      "MAE 0.09824761979727789 \n",
      " 1-MAE 0.9017523802027221 \n",
      "\n",
      "interview\n",
      "MAE 0.09714372608795334 \n",
      " 1-MAE 0.9028562739120467 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_six=[\"extraverasion\",\"neurocitism\",\"agreeableness\",\"conscientoiusness\",\"openess\",\"interview\"]\n",
    "for i in range(6):\n",
    "    print(big_six[i])\n",
    "    mae=mean_absolute_error(val_y.values[:,i],y_pred_validation[:,i])\n",
    "    one_mae=1-mae\n",
    "    print(\"MAE\",mae,\"\\n\",\"1-MAE\",one_mae,\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10030068270117037"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test=final_model.predict([test_audio_scaled.values,test_video_scaled.values,test_text_scaled.values])\n",
    "mae=mean_absolute_error(test_y.values,y_pred_test)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraverasion\n",
      "MAE 0.0994608104034507 \n",
      " 1-MAE 0.9005391895965493 \n",
      "\n",
      "neurocitism\n",
      "MAE 0.10164838937826862 \n",
      " 1-MAE 0.8983516106217314 \n",
      "\n",
      "agreeableness\n",
      "MAE 0.09543551254816848 \n",
      " 1-MAE 0.9045644874518315 \n",
      "\n",
      "conscientoiusness\n",
      "MAE 0.10799166524439617 \n",
      " 1-MAE 0.8920083347556038 \n",
      "\n",
      "openess\n",
      "MAE 0.09960609436194258 \n",
      " 1-MAE 0.9003939056380574 \n",
      "\n",
      "interview\n",
      "MAE 0.09766162427079583 \n",
      " 1-MAE 0.9023383757292042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "big_six=[\"extraverasion\",\"neurocitism\",\"agreeableness\",\"conscientoiusness\",\"openess\",\"interview\"]\n",
    "for i in range(6):\n",
    "    print(big_six[i])\n",
    "    mae=mean_absolute_error(test_y.values[:,i],y_pred_test[:,i])\n",
    "    one_mae=1-mae\n",
    "    print(\"MAE\",mae,\"\\n\",\"1-MAE\",one_mae,\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "Low Thresholds: [0.39252336 0.44791667 0.48351648 0.4368932  0.48888889 0.43925234]\n",
      "Mid Thresholds: [0.45794393 0.51041667 0.53846154 0.50485437 0.55555556 0.48598131]\n",
      "High Thresholds: [0.51401869 0.5625     0.59340659 0.58252427 0.61111111 0.53271028]\n",
      "\n",
      "Cluster 1\n",
      "Low Thresholds: [0.56074766 0.61458333 0.61538462 0.58252427 0.64444444 0.60747664]\n",
      "Mid Thresholds: [0.62616822 0.66666667 0.67032967 0.66019417 0.7        0.64953271]\n",
      "High Thresholds: [0.68224299 0.72916667 0.72527473 0.72815534 0.76666667 0.71028037]\n",
      "\n",
      "Cluster 2\n",
      "Low Thresholds: [0.23364486 0.26041667 0.31868132 0.27184466 0.32222222 0.25233645]\n",
      "Mid Thresholds: [0.29906542 0.32291667 0.38461538 0.33980583 0.38888889 0.30841121]\n",
      "High Thresholds: [0.35514019 0.38541667 0.45054945 0.40776699 0.45555556 0.35514019]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.9.4inst\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  \n",
    "cluster_labels = kmeans.fit_predict(train_y)\n",
    "\n",
    "thresholds = []\n",
    "for i in range(kmeans.n_clusters):\n",
    "    cluster_data = train_y[cluster_labels == i]\n",
    "    cluster_thresholds = np.percentile(cluster_data, [ 25,50, 75,100], axis=0) \n",
    "    thresholds.append(('Cluster {}'.format(i), cluster_thresholds))\n",
    "\n",
    "for cluster, cluster_thresholds in thresholds:\n",
    "    print(cluster)\n",
    "    print('Low Thresholds:', cluster_thresholds[0])\n",
    "    print('Mid Thresholds:', cluster_thresholds[1])\n",
    "    print('High Thresholds:', cluster_thresholds[2])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
